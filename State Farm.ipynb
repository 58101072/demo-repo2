{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Farm Classification Exercise\n",
    "## 1. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 loading and exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "Train = pd.read_csv(os.path.join(os.getcwd(), \"exercise_40_train.csv\"), header = 0)\n",
    "Test = pd.read_csv(os.path.join(os.getcwd(), \"exercise_40_test.csv\"), header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Test and Trian to Main for data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main = pd.concat([Test.assign(ind=\"test\"), Train.assign(ind=\"train\")])\n",
    "#test, train = df[df[\"ind\"].eq(\"test\")], df[df[\"ind\"].eq(\"train\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>x100</th>\n",
       "      <th>ind</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.747627</td>\n",
       "      <td>20.509439</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2.299105</td>\n",
       "      <td>-1.815777</td>\n",
       "      <td>-0.752166</td>\n",
       "      <td>0.0098%</td>\n",
       "      <td>-3.240309</td>\n",
       "      <td>0.587948</td>\n",
       "      <td>-0.260721</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>3.107683</td>\n",
       "      <td>0.533904</td>\n",
       "      <td>12.438759</td>\n",
       "      <td>7.298306</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.567120</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.148654</td>\n",
       "      <td>19.301465</td>\n",
       "      <td>Fri</td>\n",
       "      <td>1.862200</td>\n",
       "      <td>-0.773707</td>\n",
       "      <td>-1.461276</td>\n",
       "      <td>0.0076%</td>\n",
       "      <td>0.443209</td>\n",
       "      <td>0.522113</td>\n",
       "      <td>-1.090886</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.276078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.386987</td>\n",
       "      <td>12.527094</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>98.607486</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.986860</td>\n",
       "      <td>18.769675</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1.040845</td>\n",
       "      <td>-1.548690</td>\n",
       "      <td>2.632948</td>\n",
       "      <td>-5e-04%</td>\n",
       "      <td>-1.167885</td>\n",
       "      <td>5.739275</td>\n",
       "      <td>0.222975</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>2.090868</td>\n",
       "      <td>-1.780474</td>\n",
       "      <td>11.328177</td>\n",
       "      <td>11.628247</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>94.578246</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.709183</td>\n",
       "      <td>18.374375</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>-0.169882</td>\n",
       "      <td>-2.396549</td>\n",
       "      <td>-0.784673</td>\n",
       "      <td>-0.016%</td>\n",
       "      <td>-2.662226</td>\n",
       "      <td>1.548050</td>\n",
       "      <td>0.210141</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>2.643847</td>\n",
       "      <td>1.662240</td>\n",
       "      <td>10.064961</td>\n",
       "      <td>10.550014</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.346261</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.801616</td>\n",
       "      <td>20.205541</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2.092652</td>\n",
       "      <td>-0.732784</td>\n",
       "      <td>-0.703101</td>\n",
       "      <td>0.0186%</td>\n",
       "      <td>0.056422</td>\n",
       "      <td>2.878167</td>\n",
       "      <td>-0.457618</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.074434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.255766</td>\n",
       "      <td>12.716137</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>102.578918</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1         x2         x3        x4        x5        x6       x7  \\\n",
       "0  4.747627  20.509439  Wednesday  2.299105 -1.815777 -0.752166  0.0098%   \n",
       "1  1.148654  19.301465        Fri  1.862200 -0.773707 -1.461276  0.0076%   \n",
       "2  4.986860  18.769675   Saturday  1.040845 -1.548690  2.632948  -5e-04%   \n",
       "3  3.709183  18.374375    Tuesday -0.169882 -2.396549 -0.784673  -0.016%   \n",
       "4  3.801616  20.205541     Monday  2.092652 -0.732784 -0.703101  0.0186%   \n",
       "\n",
       "         x8        x9       x10  ...  x93       x94       x95        x96  \\\n",
       "0 -3.240309  0.587948 -0.260721  ...   no  3.107683  0.533904  12.438759   \n",
       "1  0.443209  0.522113 -1.090886  ...  yes  4.276078       NaN  10.386987   \n",
       "2 -1.167885  5.739275  0.222975  ...   no  2.090868 -1.780474  11.328177   \n",
       "3 -2.662226  1.548050  0.210141  ...   no  2.643847  1.662240  10.064961   \n",
       "4  0.056422  2.878167 -0.457618  ...  yes  4.074434       NaN   9.255766   \n",
       "\n",
       "         x97  x98  x99        x100   ind   y  \n",
       "0   7.298306    0  NaN   93.567120  test NaN  \n",
       "1  12.527094    1  yes   98.607486  test NaN  \n",
       "2  11.628247    0  yes   94.578246  test NaN  \n",
       "3  10.550014    1  NaN  100.346261  test NaN  \n",
       "4  12.716137    1  yes  102.578918  test NaN  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 0 to 39999\n",
      "Columns: 102 entries, x1 to y\n",
      "dtypes: float64(87), int64(2), object(13)\n",
      "memory usage: 39.3+ MB\n"
     ]
    }
   ],
   "source": [
    "Main.info(null_counts='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 cleaning object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 0 to 39999\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   x3      50000 non-null  object\n",
      " 1   x7      50000 non-null  object\n",
      " 2   x19     50000 non-null  object\n",
      " 3   x24     45175 non-null  object\n",
      " 4   x31     50000 non-null  object\n",
      " 5   x33     41059 non-null  object\n",
      " 6   x39     50000 non-null  object\n",
      " 7   x60     50000 non-null  object\n",
      " 8   x65     50000 non-null  object\n",
      " 9   x77     38425 non-null  object\n",
      " 10  x93     50000 non-null  object\n",
      " 11  x99     33864 non-null  object\n",
      " 12  ind     50000 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#find the object features with null\n",
    "Main.loc[:, Main.dtypes == np.object].info(null_counts='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x3</th>\n",
       "      <th>x7</th>\n",
       "      <th>x19</th>\n",
       "      <th>x24</th>\n",
       "      <th>x31</th>\n",
       "      <th>x33</th>\n",
       "      <th>x39</th>\n",
       "      <th>x60</th>\n",
       "      <th>x65</th>\n",
       "      <th>x77</th>\n",
       "      <th>x93</th>\n",
       "      <th>x99</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.0098%</td>\n",
       "      <td>$120.216189955777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>Florida</td>\n",
       "      <td>5-10 miles</td>\n",
       "      <td>May</td>\n",
       "      <td>progressive</td>\n",
       "      <td>mercedes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri</td>\n",
       "      <td>0.0076%</td>\n",
       "      <td>$-267.562586413086</td>\n",
       "      <td>female</td>\n",
       "      <td>yes</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>5-10 miles</td>\n",
       "      <td>July</td>\n",
       "      <td>allstate</td>\n",
       "      <td>ford</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>-5e-04%</td>\n",
       "      <td>$-311.292903116571</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-10 miles</td>\n",
       "      <td>January</td>\n",
       "      <td>progressive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>-0.016%</td>\n",
       "      <td>$2229.14940030076</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>5-10 miles</td>\n",
       "      <td>July</td>\n",
       "      <td>geico</td>\n",
       "      <td>subaru</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monday</td>\n",
       "      <td>0.0186%</td>\n",
       "      <td>$-469.049529991235</td>\n",
       "      <td>female</td>\n",
       "      <td>yes</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>5-10 miles</td>\n",
       "      <td>January</td>\n",
       "      <td>progressive</td>\n",
       "      <td>ford</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x3       x7                 x19     x24  x31             x33  \\\n",
       "0  Wednesday  0.0098%   $120.216189955777     NaN   no         Florida   \n",
       "1        Fri  0.0076%  $-267.562586413086  female  yes  North Carolina   \n",
       "2   Saturday  -5e-04%  $-311.292903116571    male   no             NaN   \n",
       "3    Tuesday  -0.016%   $2229.14940030076  female   no     Mississippi   \n",
       "4     Monday  0.0186%  $-469.049529991235  female  yes         Georgia   \n",
       "\n",
       "          x39      x60          x65       x77  x93  x99   ind  \n",
       "0  5-10 miles      May  progressive  mercedes   no  NaN  test  \n",
       "1  5-10 miles     July     allstate      ford  yes  yes  test  \n",
       "2  5-10 miles  January  progressive       NaN   no  yes  test  \n",
       "3  5-10 miles     July        geico    subaru   no  NaN  test  \n",
       "4  5-10 miles  January  progressive      ford  yes  yes  test  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.loc[:, Main.dtypes == np.object].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore X3 and replace full name with Abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wednesday    6154\n",
       "Monday       5149\n",
       "Friday       5064\n",
       "Tuesday      4925\n",
       "Sunday       4563\n",
       "Saturday     4442\n",
       "Tue          3636\n",
       "Thursday     3493\n",
       "Mon          2722\n",
       "Wed          2567\n",
       "Sat          2212\n",
       "Thur         2069\n",
       "Fri          2002\n",
       "Sun          1002\n",
       "Name: x3, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main.x3=Train.x3.replace(['Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday','Saturday','Sunday'], \n",
    "                 ['Mon', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat', 'Sun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wed     8708\n",
       "Tue     8557\n",
       "Mon     7954\n",
       "Fri     7012\n",
       "Sat     6734\n",
       "Thur    5546\n",
       "Sun     5489\n",
       "Name: x3, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x3.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert X7 to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main['x7'] = Main['x7'].str.rstrip('%').astype('float') / 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove '$' from x19 and convert to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Main['x19'] = Main['x19'].str.replace(',', '').str.replace('$', '').astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore X24 and fill null with 'unknown_gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    22690\n",
       "male      22485\n",
       "NaN        4825\n",
       "Name: x24, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x24.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Main.x24=Main.x24.fillna('unknown_gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female            22690\n",
       "male              22485\n",
       "unknown_gender     4825\n",
       "Name: x24, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x24.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore X31 and replace no with 0, yes with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     42522\n",
       "yes     7478\n",
       "Name: x31, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x31.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main.x31=Train.x31.replace(['no', 'yes'], [ 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    42543\n",
       "1     7457\n",
       "Name: x31, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x31.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore X33 and fill null with 'unknown_state'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN               8941\n",
       "California        4234\n",
       "Texas             2845\n",
       "Florida           2277\n",
       "New York          2176\n",
       "Pennsylvania      1554\n",
       "Illinois          1546\n",
       "Ohio              1392\n",
       "Michigan          1227\n",
       "Georgia           1154\n",
       "North Carolina    1148\n",
       "New Jersey        1074\n",
       "Virginia           979\n",
       "Washington         939\n",
       "Tennessee          847\n",
       "Indiana            836\n",
       "Massachusetts      816\n",
       "Arizona            789\n",
       "Missouri           787\n",
       "Wisconsin          780\n",
       "Minnesota          759\n",
       "Maryland           720\n",
       "Alabama            703\n",
       "Colorado           690\n",
       "South Carolina     623\n",
       "Louisiana          620\n",
       "Kentucky           592\n",
       "Oregon             554\n",
       "Oklahoma           550\n",
       "Connecticut        522\n",
       "Utah               479\n",
       "Kansas             465\n",
       "Nevada             461\n",
       "Arkansas           459\n",
       "Mississippi        446\n",
       "Iowa               442\n",
       "Nebraska           400\n",
       "New Mexico         395\n",
       "West Virginia      370\n",
       "Idaho              344\n",
       "Hawaii             328\n",
       "New Hampshire      304\n",
       "Rhode Island       303\n",
       "Maine              301\n",
       "Vermont            236\n",
       "Montana            235\n",
       "South Dakota       233\n",
       "Wyoming            230\n",
       "DC                 230\n",
       "North Dakota       229\n",
       "Alaska             221\n",
       "Delaware           215\n",
       "Name: x33, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x33.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main.x33=Main.x33.fillna('unknown_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown_state     8941\n",
       "California        4234\n",
       "Texas             2845\n",
       "Florida           2277\n",
       "New York          2176\n",
       "Pennsylvania      1554\n",
       "Illinois          1546\n",
       "Ohio              1392\n",
       "Michigan          1227\n",
       "Georgia           1154\n",
       "North Carolina    1148\n",
       "New Jersey        1074\n",
       "Virginia           979\n",
       "Washington         939\n",
       "Tennessee          847\n",
       "Indiana            836\n",
       "Massachusetts      816\n",
       "Arizona            789\n",
       "Missouri           787\n",
       "Wisconsin          780\n",
       "Minnesota          759\n",
       "Maryland           720\n",
       "Alabama            703\n",
       "Colorado           690\n",
       "South Carolina     623\n",
       "Louisiana          620\n",
       "Kentucky           592\n",
       "Oregon             554\n",
       "Oklahoma           550\n",
       "Connecticut        522\n",
       "Utah               479\n",
       "Kansas             465\n",
       "Nevada             461\n",
       "Arkansas           459\n",
       "Mississippi        446\n",
       "Iowa               442\n",
       "Nebraska           400\n",
       "New Mexico         395\n",
       "West Virginia      370\n",
       "Idaho              344\n",
       "Hawaii             328\n",
       "New Hampshire      304\n",
       "Rhode Island       303\n",
       "Maine              301\n",
       "Vermont            236\n",
       "Montana            235\n",
       "South Dakota       233\n",
       "Wyoming            230\n",
       "DC                 230\n",
       "North Dakota       229\n",
       "Alaska             221\n",
       "Delaware           215\n",
       "Name: x33, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x33.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore x39. That column contains only one value. So, the column can be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-10 miles    50000\n",
       "Name: x39, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x39.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main = Main.drop(['x39'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore X60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "December     8136\n",
       "January      7922\n",
       "July         7912\n",
       "August       7907\n",
       "June         1272\n",
       "September    1245\n",
       "February     1213\n",
       "November     1043\n",
       "April         951\n",
       "March         807\n",
       "May           799\n",
       "October       793\n",
       "Name: x60, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.x60.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore X65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "progressive    10877\n",
       "allstate       10859\n",
       "esurance        7144\n",
       "farmers         5600\n",
       "geico           5520\n",
       "Name: x65, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.x65.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore X77 and fill null with 'unknown_vendor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN          9257\n",
       "ford         9005\n",
       "subaru       5047\n",
       "chevrolet    5011\n",
       "mercedes     4494\n",
       "toyota       3555\n",
       "nissan       2575\n",
       "buick        1056\n",
       "Name: x77, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.x77.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main.x77=Main.x77.fillna('unknown_vendor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore X93. Replace 'no' with 0, 'yes' with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     44354\n",
       "yes     5646\n",
       "Name: x93, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x93.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main.x93=Train.x93.replace(['no', 'yes'], [ 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    44374\n",
       "1     5626\n",
       "Name: x93, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x93.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore X99. Replace 'yes' with 1. Fill NaN with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    33864\n",
       "NaN    16136\n",
       "Name: x99, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x99.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main.x99=Main.x99.replace(['yes'], [1])\n",
    "Main.x99=Main.x99.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    33864\n",
       "0.0    16136\n",
       "Name: x99, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main.x99.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 0 to 39999\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   x3      50000 non-null  object\n",
      " 1   x24     50000 non-null  object\n",
      " 2   x33     50000 non-null  object\n",
      " 3   x60     50000 non-null  object\n",
      " 4   x65     50000 non-null  object\n",
      " 5   x77     50000 non-null  object\n",
      " 6   ind     50000 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#check the object features with null\n",
    "Main.loc[:, Main.dtypes == np.object].info(null_counts='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x3</th>\n",
       "      <th>x24</th>\n",
       "      <th>x33</th>\n",
       "      <th>x60</th>\n",
       "      <th>x65</th>\n",
       "      <th>x77</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed</td>\n",
       "      <td>unknown_gender</td>\n",
       "      <td>Florida</td>\n",
       "      <td>May</td>\n",
       "      <td>progressive</td>\n",
       "      <td>mercedes</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri</td>\n",
       "      <td>female</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>July</td>\n",
       "      <td>allstate</td>\n",
       "      <td>ford</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thur</td>\n",
       "      <td>male</td>\n",
       "      <td>unknown_state</td>\n",
       "      <td>January</td>\n",
       "      <td>progressive</td>\n",
       "      <td>unknown_vendor</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue</td>\n",
       "      <td>female</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>July</td>\n",
       "      <td>geico</td>\n",
       "      <td>subaru</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun</td>\n",
       "      <td>female</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>January</td>\n",
       "      <td>progressive</td>\n",
       "      <td>ford</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x3             x24             x33      x60          x65             x77  \\\n",
       "0   Wed  unknown_gender         Florida      May  progressive        mercedes   \n",
       "1   Fri          female  North Carolina     July     allstate            ford   \n",
       "2  Thur            male   unknown_state  January  progressive  unknown_vendor   \n",
       "3   Tue          female     Mississippi     July        geico          subaru   \n",
       "4   Sun          female         Georgia  January  progressive            ford   \n",
       "\n",
       "    ind  \n",
       "0  test  \n",
       "1  test  \n",
       "2  test  \n",
       "3  test  \n",
       "4  test  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the new object features\n",
    "Main.loc[:, Main.dtypes == np.object].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 0 to 39999\n",
      "Columns: 101 entries, x1 to y\n",
      "dtypes: float64(90), int64(4), object(7)\n",
      "memory usage: 38.9+ MB\n"
     ]
    }
   ],
   "source": [
    "Main.info(null_counts='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x31</th>\n",
       "      <th>x59</th>\n",
       "      <th>x93</th>\n",
       "      <th>x98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x31  x59  x93  x98\n",
       "0    0    0    0    0\n",
       "1    0    0    0    1\n",
       "2    0    0    0    0\n",
       "3    0    0    0    1\n",
       "4    1    0    1    1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the new object features\n",
    "Main.loc[:, Main.dtypes == np.int64].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Identify columns that may need further transformation:\n",
    "\n",
    "Constant features (note: Binary 1/0, 'ind' test/train and 'y'. no transformation needed)\n",
    "\n",
    "Categorical features for one-hot encoding (that are not already binary or one-hot encoded)\n",
    "\n",
    "Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_feat = list(Main.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constant features\n",
    "con_feat = ['x31','x59','x93','x98','x99','ind','y'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features that are *not* already binary or one-hot encoded\n",
    "cat_feat = ['x3', 'x24', 'x33', 'x60','x65', 'x77']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_num_feat = con_feat + cat_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create Numerical featureas using all_features-(con_feat+cat_feat)\n",
    "non_num_feat = con_feat + cat_feat\n",
    "num_feat = [x for x in all_feat if (x not in non_num_feat)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check length to make sure all the features are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(con_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.3 Prepare the data transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler #, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom transformer: NoTransformer\n",
    "# Just returns the feature without transformation\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class NoTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define another custom transformer: CapFloorTransformer\n",
    "# Provides caps and floors for numerical features\n",
    "\n",
    "class CapFloorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_feature_list):\n",
    "        self.num_feature_list = num_feature_list\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        for feature in self.num_feature_list:\n",
    "            X_[feature] = np.where(X_[feature] < X_[feature].quantile(0.0005),\n",
    "                                   X_[feature].quantile(0.0005), X_[feature])\n",
    "            X_[feature] = np.where(X_[feature] > X_[feature].quantile(0.9995),\n",
    "                                   X_[feature].quantile(0.9995), X_[feature])\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline for numerical features\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('cap_floor', CapFloorTransformer(num_feature_list=num_feat)),\n",
    "    ('min_max', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define data transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "    ('no_trans', NoTransformer(), con_feat),\n",
    "    ('categorical', OneHotEncoder(), cat_feat),\n",
    "    ('numerical', num_pipeline, num_feat)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Run the pipeline to fit and transform Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.84 s, sys: 351 ms, total: 2.19 s\n",
      "Wall time: 972 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Run pipeline fit_transform -- takes ~ 90 sec\n",
    "Main_prepared = full_pipeline.fit_transform(Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 182)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0.5389060542036326, 0.2954983093304213,\n",
       "        0.3048764763602221],\n",
       "       [0, 0, 0, ..., 0.2772212679288337, 0.6879797078577634,\n",
       "        0.4520051258250257],\n",
       "       [0, 0, 0, ..., 0.397261459526135, 0.620510778610277,\n",
       "        0.3343913177068121],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0.5141453972092866, 0.3229301108227761,\n",
       "        0.49331053805603675],\n",
       "       [0, 0, 0, ..., 0.21207147833186046, 0.3965486900500568,\n",
       "        0.7687971899910235],\n",
       "       [0, 1, 0, ..., 0.06814300929219064, 0.6878870817949392,\n",
       "        0.7943314687075262]], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Store prepared data in a pandas DataFrame:\n",
    "\n",
    "Find column names for transformed data (including one-hot transformed features)\n",
    "\n",
    "Find transformed column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names for transformed df:\n",
    "trans_col_names = []\n",
    "\n",
    "for i in range(len(full_pipeline.transformers_)):\n",
    "    trans = full_pipeline.transformers_[i][1]\n",
    "    \n",
    "    # Check if transformer is OHE instance\n",
    "    if isinstance(trans, OneHotEncoder):\n",
    "        \n",
    "        # Create list of feature names for OHE transformer\n",
    "        # Use .get_feature_names() from transformers_ and remove 'x0_' etc. from feature names by using only [3:]\n",
    "        feat_names = [feat_name[3:] for feat_name in trans.get_feature_names()]\n",
    "    else:\n",
    "        \n",
    "        # For non-OHE instances, access the feature names in full_pipeline.transformers_[i][2]\n",
    "        feat_names = [feat_name for feat_name in full_pipeline.transformers_[i][2]]\n",
    "        \n",
    "    trans_col_names += feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "Main_transformed = pd.DataFrame(Main_prepared, columns=trans_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x31</th>\n",
       "      <th>x59</th>\n",
       "      <th>x93</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>ind</th>\n",
       "      <th>y</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Sat</th>\n",
       "      <th>...</th>\n",
       "      <th>x88</th>\n",
       "      <th>x89</th>\n",
       "      <th>x90</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866722</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.891929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907117</td>\n",
       "      <td>0.355609</td>\n",
       "      <td>0.531887</td>\n",
       "      <td>0.538906</td>\n",
       "      <td>0.295498</td>\n",
       "      <td>0.304876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447324</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.756481</td>\n",
       "      <td>0.416633</td>\n",
       "      <td>0.591244</td>\n",
       "      <td>0.47562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.277221</td>\n",
       "      <td>0.68798</td>\n",
       "      <td>0.452005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700983</td>\n",
       "      <td>0.620915</td>\n",
       "      <td>0.785095</td>\n",
       "      <td>0.251167</td>\n",
       "      <td>0.334468</td>\n",
       "      <td>0.397261</td>\n",
       "      <td>0.620511</td>\n",
       "      <td>0.334391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469652</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>0.634022</td>\n",
       "      <td>0.574792</td>\n",
       "      <td>0.392599</td>\n",
       "      <td>0.307966</td>\n",
       "      <td>0.628135</td>\n",
       "      <td>0.23615</td>\n",
       "      <td>0.539577</td>\n",
       "      <td>0.50276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532595</td>\n",
       "      <td>0.15618</td>\n",
       "      <td>0.329675</td>\n",
       "      <td>0.418049</td>\n",
       "      <td>0.378916</td>\n",
       "      <td>0.454908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.132944</td>\n",
       "      <td>0.70217</td>\n",
       "      <td>0.567932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  x31 x59 x93 x98  x99   ind    y  Fri  Mon  Sat  ...       x88       x89  \\\n",
       "0   0   0   0   0  0.0  test  NaN  0.0  0.0  0.0  ...  0.866722  0.217677   \n",
       "1   0   0   0   1  1.0  test  NaN  1.0  0.0  0.0  ...  0.447324  0.004173   \n",
       "2   0   0   0   0  1.0  test  NaN  0.0  0.0  0.0  ...  0.638263       NaN   \n",
       "3   0   0   0   1  0.0  test  NaN  0.0  0.0  0.0  ...  0.469652  0.483384   \n",
       "4   1   0   1   1  1.0  test  NaN  0.0  0.0  0.0  ...  0.532595   0.15618   \n",
       "\n",
       "        x90       x91       x92       x94       x95       x96       x97  \\\n",
       "0  0.891929       NaN  0.907117  0.355609  0.531887  0.538906  0.295498   \n",
       "1  0.756481  0.416633  0.591244   0.47562       NaN  0.277221   0.68798   \n",
       "2  0.700983  0.620915  0.785095  0.251167  0.334468  0.397261  0.620511   \n",
       "3  0.634022  0.574792  0.392599  0.307966  0.628135   0.23615  0.539577   \n",
       "4  0.329675  0.418049  0.378916  0.454908       NaN  0.132944   0.70217   \n",
       "\n",
       "       x100  \n",
       "0  0.304876  \n",
       "1  0.452005  \n",
       "2  0.334391  \n",
       "3   0.50276  \n",
       "4  0.567932  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Fill remaining Nan with -1\n",
    "\n",
    "(For the test y, I'll drop the column later. So, I don't care for now.)\n",
    "\n",
    "Remaining NaN values should only be numerical at this point.\n",
    "Since numerical features have already been transformed by MinMaxScaler, now we can fill NaN with -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall minimum numerical value\n",
    "np.min(Main_transformed[num_feat].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall maximum numerical value\n",
    "np.max(Main_transformed[num_feat].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.05 s, sys: 160 ms, total: 3.21 s\n",
      "Wall time: 2.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fill NaN values with -1\n",
    "Main_transformed = Main_transformed.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x31</th>\n",
       "      <th>x59</th>\n",
       "      <th>x93</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>ind</th>\n",
       "      <th>y</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Sat</th>\n",
       "      <th>...</th>\n",
       "      <th>x88</th>\n",
       "      <th>x89</th>\n",
       "      <th>x90</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866722</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.891929</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.907117</td>\n",
       "      <td>0.355609</td>\n",
       "      <td>0.531887</td>\n",
       "      <td>0.538906</td>\n",
       "      <td>0.295498</td>\n",
       "      <td>0.304876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447324</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.756481</td>\n",
       "      <td>0.416633</td>\n",
       "      <td>0.591244</td>\n",
       "      <td>0.475620</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.277221</td>\n",
       "      <td>0.687980</td>\n",
       "      <td>0.452005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638263</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.700983</td>\n",
       "      <td>0.620915</td>\n",
       "      <td>0.785095</td>\n",
       "      <td>0.251167</td>\n",
       "      <td>0.334468</td>\n",
       "      <td>0.397261</td>\n",
       "      <td>0.620511</td>\n",
       "      <td>0.334391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469652</td>\n",
       "      <td>0.483384</td>\n",
       "      <td>0.634022</td>\n",
       "      <td>0.574792</td>\n",
       "      <td>0.392599</td>\n",
       "      <td>0.307966</td>\n",
       "      <td>0.628135</td>\n",
       "      <td>0.236150</td>\n",
       "      <td>0.539577</td>\n",
       "      <td>0.502760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532595</td>\n",
       "      <td>0.156180</td>\n",
       "      <td>0.329675</td>\n",
       "      <td>0.418049</td>\n",
       "      <td>0.378916</td>\n",
       "      <td>0.454908</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.132944</td>\n",
       "      <td>0.702170</td>\n",
       "      <td>0.567932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x31  x59  x93  x98  x99   ind    y  Fri  Mon  Sat  ...       x88       x89  \\\n",
       "0    0    0    0    0  0.0  test -1.0  0.0  0.0  0.0  ...  0.866722  0.217677   \n",
       "1    0    0    0    1  1.0  test -1.0  1.0  0.0  0.0  ...  0.447324  0.004173   \n",
       "2    0    0    0    0  1.0  test -1.0  0.0  0.0  0.0  ...  0.638263 -1.000000   \n",
       "3    0    0    0    1  0.0  test -1.0  0.0  0.0  0.0  ...  0.469652  0.483384   \n",
       "4    1    0    1    1  1.0  test -1.0  0.0  0.0  0.0  ...  0.532595  0.156180   \n",
       "\n",
       "        x90       x91       x92       x94       x95       x96       x97  \\\n",
       "0  0.891929 -1.000000  0.907117  0.355609  0.531887  0.538906  0.295498   \n",
       "1  0.756481  0.416633  0.591244  0.475620 -1.000000  0.277221  0.687980   \n",
       "2  0.700983  0.620915  0.785095  0.251167  0.334468  0.397261  0.620511   \n",
       "3  0.634022  0.574792  0.392599  0.307966  0.628135  0.236150  0.539577   \n",
       "4  0.329675  0.418049  0.378916  0.454908 -1.000000  0.132944  0.702170   \n",
       "\n",
       "       x100  \n",
       "0  0.304876  \n",
       "1  0.452005  \n",
       "2  0.334391  \n",
       "3  0.502760  \n",
       "4  0.567932  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed, train_transformed = Main_transformed[Main_transformed[\"ind\"].eq(\"test\")], Main_transformed[Main_transformed[\"ind\"].eq(\"train\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop column 'ind' for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformed = train_transformed.drop(['ind'], axis=1)\n",
    "test_transformed = test_transformed.drop(['ind'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x31</th>\n",
       "      <th>x59</th>\n",
       "      <th>x93</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>y</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>...</th>\n",
       "      <th>x88</th>\n",
       "      <th>x89</th>\n",
       "      <th>x90</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552565</td>\n",
       "      <td>0.179670</td>\n",
       "      <td>0.479024</td>\n",
       "      <td>0.462899</td>\n",
       "      <td>0.217523</td>\n",
       "      <td>0.600563</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.260461</td>\n",
       "      <td>0.320225</td>\n",
       "      <td>0.616750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571926</td>\n",
       "      <td>0.171904</td>\n",
       "      <td>0.601845</td>\n",
       "      <td>0.570998</td>\n",
       "      <td>0.702668</td>\n",
       "      <td>0.380131</td>\n",
       "      <td>0.854944</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.536219</td>\n",
       "      <td>0.528575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360281</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.640605</td>\n",
       "      <td>0.714877</td>\n",
       "      <td>0.181699</td>\n",
       "      <td>0.494158</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.069022</td>\n",
       "      <td>0.333980</td>\n",
       "      <td>0.765440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644036</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.500483</td>\n",
       "      <td>0.595892</td>\n",
       "      <td>0.517615</td>\n",
       "      <td>0.457536</td>\n",
       "      <td>0.584533</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.436616</td>\n",
       "      <td>0.580864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279920</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.498980</td>\n",
       "      <td>0.811686</td>\n",
       "      <td>0.225621</td>\n",
       "      <td>0.368587</td>\n",
       "      <td>0.663337</td>\n",
       "      <td>0.226207</td>\n",
       "      <td>0.626097</td>\n",
       "      <td>0.286160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x31  x59  x93  x98  x99    y  Fri  Mon  Sat  Sun  ...       x88  \\\n",
       "10000    0    0    0    0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.552565   \n",
       "10001    0    0    0    1  1.0  1.0  1.0  0.0  0.0  0.0  ...  0.571926   \n",
       "10002    0    0    0    0  1.0  1.0  0.0  0.0  0.0  0.0  ...  0.360281   \n",
       "10003    0    0    0    1  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.644036   \n",
       "10004    1    0    1    0  1.0  0.0  0.0  0.0  0.0  1.0  ...  0.279920   \n",
       "\n",
       "            x89       x90       x91       x92       x94       x95       x96  \\\n",
       "10000  0.179670  0.479024  0.462899  0.217523  0.600563 -1.000000  0.260461   \n",
       "10001  0.171904  0.601845  0.570998  0.702668  0.380131  0.854944 -1.000000   \n",
       "10002 -1.000000  0.640605  0.714877  0.181699  0.494158 -1.000000  0.069022   \n",
       "10003 -1.000000  0.500483  0.595892  0.517615  0.457536  0.584533 -1.000000   \n",
       "10004 -1.000000  0.498980  0.811686  0.225621  0.368587  0.663337  0.226207   \n",
       "\n",
       "            x97      x100  \n",
       "10000  0.320225  0.616750  \n",
       "10001  0.536219  0.528575  \n",
       "10002  0.333980  0.765440  \n",
       "10003  0.436616  0.580864  \n",
       "10004  0.626097  0.286160  \n",
       "\n",
       "[5 rows x 181 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data locally\n",
    "# train_transformed.to_pickle(os.path.join('train_transformed_minmax_final.pkl'))\n",
    "# test_transformed.to_pickle(os.path.join('test_transformed_minmax_final.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    34197\n",
       "1.0     5803\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transformed.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Modeling \n",
    "Create X & y objects with train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = train_transformed.drop(['y'], axis=1)\n",
    "y = train_transformed.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 180)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate X_train, X_test, y_train & y_test. Use 80% for train & 20% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state = 365) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classification model:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import other tools:\n",
    "from sklearn.metrics import precision_recall_curve, auc, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Run quick logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Default hyperparameters\n",
    "print(LR.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.8 s, sys: 174 ms, total: 1.98 s\n",
      "Wall time: 507 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fit model\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick logistic regression accuracy: \t0.8590\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy score for training prediction:\n",
    "LR_Q_train_accuracy = LR.score(X_train, y_train)\n",
    "\n",
    "print('quick logistic regression accuracy: \\t%0.4f' % LR_Q_train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Tune hyperparameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters to search\n",
    "LR_param_grid = {'penalty' : ['l1', 'l2'],\n",
    "              'C' : [1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "              'solver' : ['liblinear','lbfgs']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_grid_search = GridSearchCV(estimator=LR,\n",
    "                           param_grid=LR_param_grid,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 45s, sys: 12.1 s, total: 3min 57s\n",
      "Wall time: 2min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(multi_class='ovr'),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear', 'lbfgs']})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit\n",
    "LR_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_best = LR_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 s, sys: 102 ms, total: 1.74 s\n",
      "Wall time: 439 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, multi_class='ovr')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit model\n",
    "LR_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression accuracy: \t0.8581\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy score for training prediction:\n",
    "LR_train_accuracy_best = LR_best.score(X_train, y_train)\n",
    "print('Best logistic regression accuracy: \\t%0.4f' % LR_train_accuracy_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Test optimized model against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_LR = LR_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.92      6883\n",
      "         1.0       0.53      0.06      0.11      1117\n",
      "\n",
      "    accuracy                           0.86      8000\n",
      "   macro avg       0.70      0.53      0.52      8000\n",
      "weighted avg       0.82      0.86      0.81      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_test_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6822   61]\n",
      " [1049   68]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_test_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Evaluate AUC for ROC and PR for performance against test set\n",
    "\n",
    "For imbalanced targets, area under the precision-recall curve is usually a better indicator of model performance than area under the receiver operating characteristic curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find probability estimates for y_pred_test\n",
    "y_pred_proba_test_LR = LR_best.predict_proba(X_test)[:, 1] # use second column for probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false positive rate and true positive rate:\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba_test_LR)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_proba_test_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Precision-Recall curve for clf_best:\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.step(recall, precision, label='Precision-recall curve (area = %0.4f)' % auc(recall, precision))\n",
    "plt.title('Logistic Regression model: Precision-recall curve', size=13)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='lower left', fontsize=13)\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlim([-0.05, 1.05])\n",
    "\n",
    "# Plot ROC curve for clf_best:\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.4f)' % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.title('Logistic Regression model: ROC curve', size=13)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlim([-0.05, 1.05])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7537954695120944"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Area under curve for ROC\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.350694974716933"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Area under precision-recall curve\n",
    "auc(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 DNN in Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras and Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation set from training data to evaluate model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(X_train, y_train,test_size = 0.2, random_state = 365) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pandas dataframes to NumPy arrays\n",
    "\n",
    "NOTE: In order to use validation_split or validation_data during model training, the training data should be in NumPy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train_np = X_train_train.to_numpy()\n",
    "y_train_train_np = y_train_train.to_numpy()\n",
    "X_train_val_np = X_train_val.to_numpy()\n",
    "y_train_val_np = y_train_val.to_numpy()\n",
    "\n",
    "X_test_np = X_test.to_numpy()\n",
    "y_test_np = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Run a quick DNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sequential model with 2 hidden layers\n",
    "\n",
    "DNN = keras.Sequential()\n",
    "DNN.add(layers.Dense(300, input_shape=(X_train.shape[1],), activation='relu', name='layer1'))\n",
    "DNN.add(layers.Dense(100, activation='relu', name='layer2'))\n",
    "DNN.add(layers.Dense(30, activation='relu', name='layer3'))\n",
    "DNN.add(layers.Dense(1, activation='sigmoid', name='ouput'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 300)               54300     \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "ouput (Dense)                (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 87,461\n",
      "Trainable params: 87,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "DNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25600 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "25600/25600 [==============================] - 2s 72us/sample - loss: 0.3952 - accuracy: 0.8527 - AUC: 0.6639 - val_loss: 0.3768 - val_accuracy: 0.8550 - val_AUC: 0.7191\n",
      "Epoch 2/20\n",
      "25600/25600 [==============================] - 1s 44us/sample - loss: 0.3700 - accuracy: 0.8546 - AUC: 0.7362 - val_loss: 0.3691 - val_accuracy: 0.8558 - val_AUC: 0.7346\n",
      "Epoch 3/20\n",
      "25600/25600 [==============================] - 1s 44us/sample - loss: 0.3585 - accuracy: 0.8575 - AUC: 0.7616 - val_loss: 0.3719 - val_accuracy: 0.8552 - val_AUC: 0.7321\n",
      "Epoch 4/20\n",
      "25600/25600 [==============================] - 1s 43us/sample - loss: 0.3491 - accuracy: 0.8620 - AUC: 0.7789 - val_loss: 0.3738 - val_accuracy: 0.8550 - val_AUC: 0.7278\n",
      "Epoch 5/20\n",
      "25600/25600 [==============================] - 1s 44us/sample - loss: 0.3361 - accuracy: 0.8645 - AUC: 0.8012 - val_loss: 0.3794 - val_accuracy: 0.8545 - val_AUC: 0.7251\n",
      "Epoch 6/20\n",
      "25600/25600 [==============================] - 1s 44us/sample - loss: 0.3188 - accuracy: 0.8720 - AUC: 0.8263 - val_loss: 0.4061 - val_accuracy: 0.8427 - val_AUC: 0.6945\n",
      "Epoch 7/20\n",
      "25600/25600 [==============================] - 1s 44us/sample - loss: 0.2940 - accuracy: 0.8815 - AUC: 0.8572 - val_loss: 0.4212 - val_accuracy: 0.8423 - val_AUC: 0.6922\n",
      "CPU times: user 15.4 s, sys: 3.09 s, total: 18.5 s\n",
      "Wall time: 8.64 s\n"
     ]
    }
   ],
   "source": [
    " %%time\n",
    "\n",
    " # Use early stopping if model does not improve after 5 epochs\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    " # Fit model\n",
    " history = DNN.fit(X_train_train_np, y_train_train_np,\n",
    "                    epochs=20,\n",
    "                    validation_data=(X_train_val_np, y_train_val_np),\n",
    "                    callbacks=[early_stopping_cb]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3618 - accuracy: 0.8619 - AUC: 0.7313\n",
      "deep neural network quick Test loss: \t0.3618\n",
      "deep neural network quick Test accuracy: \t0.8619\n",
      "deep neural network quick Test AUC: \t0.7313\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against test set\n",
    "DNN_test_loss, DNN_test_acc, DNN_test_auc = DNN.evaluate(X_test_np, y_test_np)\n",
    "print('deep neural network quick Test loss: \\t%0.4f' % DNN_test_loss)\n",
    "print('deep neural network quick Test accuracy: \\t%0.4f' % DNN_test_acc)\n",
    "print('deep neural network quick Test AUC: \\t%0.4f' % DNN_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find probability estimates\n",
    "y_pred_proba_test_quick_DNN = DNN.predict(X_test_np) # use predict for probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate false positive rate and true positive rate:\n",
    "DNN_fpr_quick, DNN_tpr_quick, DNN_thresholds_roc_quick = roc_curve(y_test_np, y_pred_proba_test_quick_DNN)\n",
    "\n",
    "# # Calculate precision and recall\n",
    "DNN_precision_quick, DNN_recall_quick, DNN_thresholds_pr_quick = precision_recall_curve(y_test_np, y_pred_proba_test_quick_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7313740300047696"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Area under curve for ROC\n",
    "auc(DNN_fpr_quick, DNN_tpr_quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3248472685689368"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Area under precision-recall curve\n",
    "auc(DNN_recall_quick, DNN_precision_quick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Tune hyperparameters for DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to build and compile model\n",
    "def build_model(n_neurons1=300, n_neurons2=100, n_hidden_add=1, n_neurons_add=50, dropout=True,\n",
    "                input_shape=(X_train.shape[1],)):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=input_shape)) # Create input layer\n",
    "    model.add(layers.Dense(n_neurons1, activation='elu')) # First hidden layer\n",
    "    model.add(layers.Dense(n_neurons2, activation='elu')) # Second hidden layer\n",
    "    for layer in range(n_hidden_add):\n",
    "        model.add(layers.Dense(n_neurons_add, activation='elu')) # Additional hidden layer(s)\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(rate=0.1)) # Optional dropout layer after last hidden layer\n",
    "    model.add(layers.Dense(1, activation='sigmoid')) # Output layer\n",
    "    optimizer = keras.optimizers.Adam(lr=0.0005)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', 'AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KerasClassifier model\n",
    "keras_clf = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "n_neurons1 = [200,300]\n",
    "n_neurons2 = [100,200]\n",
    "n_hidden_add = [2, 3]\n",
    "n_neurons_add = [30]\n",
    "dropout = [True]\n",
    "\n",
    "DNN_param_grid = dict(n_neurons1=n_neurons1,\n",
    "                  n_neurons2=n_neurons2,\n",
    "                  n_hidden_add=n_hidden_add,\n",
    "                  n_neurons_add=n_neurons_add,\n",
    "                  dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_grid_search = GridSearchCV(estimator=keras_clf,\n",
    "                               param_grid=DNN_param_grid,\n",
    "                               cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 76us/sample - loss: 0.3983 - accuracy: 0.8531 - AUC: 0.6492 - val_loss: 0.3881 - val_accuracy: 0.8556 - val_AUC: 0.7158\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 47us/sample - loss: 0.3753 - accuracy: 0.8553 - AUC: 0.7209 - val_loss: 0.3720 - val_accuracy: 0.8552 - val_AUC: 0.7328\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 47us/sample - loss: 0.3665 - accuracy: 0.8570 - AUC: 0.7420 - val_loss: 0.3690 - val_accuracy: 0.8559 - val_AUC: 0.7339\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 47us/sample - loss: 0.3631 - accuracy: 0.8572 - AUC: 0.7501 - val_loss: 0.3770 - val_accuracy: 0.8520 - val_AUC: 0.7423\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 48us/sample - loss: 0.3588 - accuracy: 0.8583 - AUC: 0.7573 - val_loss: 0.3715 - val_accuracy: 0.8564 - val_AUC: 0.7273\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 47us/sample - loss: 0.3560 - accuracy: 0.8595 - AUC: 0.7622 - val_loss: 0.3670 - val_accuracy: 0.8545 - val_AUC: 0.7403\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 46us/sample - loss: 0.3512 - accuracy: 0.8616 - AUC: 0.7711 - val_loss: 0.3750 - val_accuracy: 0.8505 - val_AUC: 0.7300\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 47us/sample - loss: 0.3479 - accuracy: 0.8611 - AUC: 0.7786 - val_loss: 0.3711 - val_accuracy: 0.8558 - val_AUC: 0.7306\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 47us/sample - loss: 0.3443 - accuracy: 0.8634 - AUC: 0.7842 - val_loss: 0.3769 - val_accuracy: 0.8562 - val_AUC: 0.7279\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 47us/sample - loss: 0.3395 - accuracy: 0.8665 - AUC: 0.7914 - val_loss: 0.3760 - val_accuracy: 0.8548 - val_AUC: 0.7209\n",
      "Epoch 11/20\n",
      "20480/20480 [==============================] - 1s 47us/sample - loss: 0.3336 - accuracy: 0.8667 - AUC: 0.8020 - val_loss: 0.3857 - val_accuracy: 0.8534 - val_AUC: 0.7217\n",
      "5120/5120 [==============================] - 0s 53us/sample - loss: 0.3680 - accuracy: 0.8518 - AUC: 0.7550\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 86us/sample - loss: 0.4024 - accuracy: 0.8522 - AUC: 0.6439 - val_loss: 0.3763 - val_accuracy: 0.8559 - val_AUC: 0.7182\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 50us/sample - loss: 0.3779 - accuracy: 0.8546 - AUC: 0.7192 - val_loss: 0.3894 - val_accuracy: 0.8552 - val_AUC: 0.7267\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 48us/sample - loss: 0.3710 - accuracy: 0.8541 - AUC: 0.7354 - val_loss: 0.3781 - val_accuracy: 0.8564 - val_AUC: 0.7357\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 49us/sample - loss: 0.3634 - accuracy: 0.8580 - AUC: 0.7520 - val_loss: 0.3655 - val_accuracy: 0.8584 - val_AUC: 0.7394\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 49us/sample - loss: 0.3610 - accuracy: 0.8586 - AUC: 0.7572 - val_loss: 0.3845 - val_accuracy: 0.8442 - val_AUC: 0.7277\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 49us/sample - loss: 0.3581 - accuracy: 0.8587 - AUC: 0.7620 - val_loss: 0.3691 - val_accuracy: 0.8564 - val_AUC: 0.7318\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 49us/sample - loss: 0.3542 - accuracy: 0.8599 - AUC: 0.7705 - val_loss: 0.3712 - val_accuracy: 0.8525 - val_AUC: 0.7335\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 49us/sample - loss: 0.3488 - accuracy: 0.8595 - AUC: 0.7807 - val_loss: 0.3845 - val_accuracy: 0.8427 - val_AUC: 0.7280\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 49us/sample - loss: 0.3462 - accuracy: 0.8636 - AUC: 0.7829 - val_loss: 0.3864 - val_accuracy: 0.8516 - val_AUC: 0.7267\n",
      "5120/5120 [==============================] - 0s 56us/sample - loss: 0.3581 - accuracy: 0.8564 - AUC: 0.7615\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 77us/sample - loss: 0.4037 - accuracy: 0.8515 - AUC: 0.6333 - val_loss: 0.3785 - val_accuracy: 0.8545 - val_AUC: 0.7153\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 48us/sample - loss: 0.3769 - accuracy: 0.8547 - AUC: 0.7169 - val_loss: 0.3685 - val_accuracy: 0.8570 - val_AUC: 0.7347\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 48us/sample - loss: 0.3665 - accuracy: 0.8566 - AUC: 0.7434 - val_loss: 0.3659 - val_accuracy: 0.8578 - val_AUC: 0.7411\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 48us/sample - loss: 0.3608 - accuracy: 0.8572 - AUC: 0.7539 - val_loss: 0.3677 - val_accuracy: 0.8553 - val_AUC: 0.7380\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 48us/sample - loss: 0.3572 - accuracy: 0.8600 - AUC: 0.7606 - val_loss: 0.3763 - val_accuracy: 0.8511 - val_AUC: 0.7353\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 48us/sample - loss: 0.3556 - accuracy: 0.8601 - AUC: 0.7634 - val_loss: 0.3758 - val_accuracy: 0.8550 - val_AUC: 0.7326\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 48us/sample - loss: 0.3499 - accuracy: 0.8620 - AUC: 0.7742 - val_loss: 0.3687 - val_accuracy: 0.8559 - val_AUC: 0.7353\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 50us/sample - loss: 0.3463 - accuracy: 0.8627 - AUC: 0.7805 - val_loss: 0.3729 - val_accuracy: 0.8497 - val_AUC: 0.7348\n",
      "5120/5120 [==============================] - 0s 59us/sample - loss: 0.3731 - accuracy: 0.8527 - AUC: 0.7444\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 81us/sample - loss: 0.4043 - accuracy: 0.8509 - AUC: 0.6376 - val_loss: 0.3792 - val_accuracy: 0.8555 - val_AUC: 0.7148\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 51us/sample - loss: 0.3796 - accuracy: 0.8538 - AUC: 0.7150 - val_loss: 0.3735 - val_accuracy: 0.8541 - val_AUC: 0.7294\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3690 - accuracy: 0.8551 - AUC: 0.7425 - val_loss: 0.3720 - val_accuracy: 0.8564 - val_AUC: 0.7364\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3637 - accuracy: 0.8564 - AUC: 0.7531 - val_loss: 0.3762 - val_accuracy: 0.8556 - val_AUC: 0.7355\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3616 - accuracy: 0.8562 - AUC: 0.7576 - val_loss: 0.3692 - val_accuracy: 0.8547 - val_AUC: 0.7387\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3584 - accuracy: 0.8579 - AUC: 0.7635 - val_loss: 0.3669 - val_accuracy: 0.8556 - val_AUC: 0.7399\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3546 - accuracy: 0.8586 - AUC: 0.7701 - val_loss: 0.3755 - val_accuracy: 0.8520 - val_AUC: 0.7309\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3507 - accuracy: 0.8597 - AUC: 0.7774 - val_loss: 0.3726 - val_accuracy: 0.8559 - val_AUC: 0.7298\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3467 - accuracy: 0.8610 - AUC: 0.7838 - val_loss: 0.3733 - val_accuracy: 0.8556 - val_AUC: 0.7281\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3428 - accuracy: 0.8634 - AUC: 0.7900 - val_loss: 0.3814 - val_accuracy: 0.8458 - val_AUC: 0.7227\n",
      "Epoch 11/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3395 - accuracy: 0.8624 - AUC: 0.7964 - val_loss: 0.3932 - val_accuracy: 0.8388 - val_AUC: 0.7217\n",
      "5120/5120 [==============================] - 0s 63us/sample - loss: 0.3606 - accuracy: 0.8580 - AUC: 0.7476\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 99us/sample - loss: 0.4002 - accuracy: 0.8524 - AUC: 0.6478 - val_loss: 0.3829 - val_accuracy: 0.8556 - val_AUC: 0.7036\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 52us/sample - loss: 0.3772 - accuracy: 0.8553 - AUC: 0.7167 - val_loss: 0.3752 - val_accuracy: 0.8525 - val_AUC: 0.7274\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20480/20480 [==============================] - 1s 51us/sample - loss: 0.3664 - accuracy: 0.8552 - AUC: 0.7445 - val_loss: 0.3744 - val_accuracy: 0.8530 - val_AUC: 0.7311\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3620 - accuracy: 0.8568 - AUC: 0.7531 - val_loss: 0.3684 - val_accuracy: 0.8566 - val_AUC: 0.7342\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3569 - accuracy: 0.8570 - AUC: 0.7632 - val_loss: 0.3714 - val_accuracy: 0.8564 - val_AUC: 0.7303\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 53us/sample - loss: 0.3528 - accuracy: 0.8599 - AUC: 0.7711 - val_loss: 0.3798 - val_accuracy: 0.8486 - val_AUC: 0.7279\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3479 - accuracy: 0.8611 - AUC: 0.7801 - val_loss: 0.3743 - val_accuracy: 0.8544 - val_AUC: 0.7240\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 54us/sample - loss: 0.3445 - accuracy: 0.8624 - AUC: 0.7843 - val_loss: 0.3794 - val_accuracy: 0.8544 - val_AUC: 0.7287\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3415 - accuracy: 0.8641 - AUC: 0.7902 - val_loss: 0.3831 - val_accuracy: 0.8444 - val_AUC: 0.7287\n",
      "5120/5120 [==============================] - 0s 62us/sample - loss: 0.3720 - accuracy: 0.8562 - AUC: 0.7347\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 88us/sample - loss: 0.3998 - accuracy: 0.8531 - AUC: 0.6496 - val_loss: 0.3758 - val_accuracy: 0.8556 - val_AUC: 0.7228\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3763 - accuracy: 0.8558 - AUC: 0.7155 - val_loss: 0.3720 - val_accuracy: 0.8544 - val_AUC: 0.7287\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3684 - accuracy: 0.8569 - AUC: 0.7364 - val_loss: 0.3714 - val_accuracy: 0.8556 - val_AUC: 0.7357\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3625 - accuracy: 0.8584 - AUC: 0.7492 - val_loss: 0.3692 - val_accuracy: 0.8553 - val_AUC: 0.7335\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3589 - accuracy: 0.8589 - AUC: 0.7579 - val_loss: 0.3697 - val_accuracy: 0.8558 - val_AUC: 0.7360\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3572 - accuracy: 0.8591 - AUC: 0.7609 - val_loss: 0.3685 - val_accuracy: 0.8556 - val_AUC: 0.7357\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3526 - accuracy: 0.8616 - AUC: 0.7684 - val_loss: 0.3740 - val_accuracy: 0.8556 - val_AUC: 0.7282\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3474 - accuracy: 0.8626 - AUC: 0.7781 - val_loss: 0.3808 - val_accuracy: 0.8487 - val_AUC: 0.7241\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3461 - accuracy: 0.8640 - AUC: 0.7795 - val_loss: 0.3726 - val_accuracy: 0.8542 - val_AUC: 0.7333\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3386 - accuracy: 0.8676 - AUC: 0.7923 - val_loss: 0.3813 - val_accuracy: 0.8555 - val_AUC: 0.7291\n",
      "Epoch 11/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3333 - accuracy: 0.8685 - AUC: 0.7993 - val_loss: 0.3834 - val_accuracy: 0.8502 - val_AUC: 0.7155\n",
      "5120/5120 [==============================] - 0s 62us/sample - loss: 0.3710 - accuracy: 0.8496 - AUC: 0.7506\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 84us/sample - loss: 0.4004 - accuracy: 0.8513 - AUC: 0.6515 - val_loss: 0.3839 - val_accuracy: 0.8552 - val_AUC: 0.7274\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3782 - accuracy: 0.8537 - AUC: 0.7178 - val_loss: 0.3694 - val_accuracy: 0.8586 - val_AUC: 0.7344\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3713 - accuracy: 0.8552 - AUC: 0.7357 - val_loss: 0.3673 - val_accuracy: 0.8570 - val_AUC: 0.7369\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 54us/sample - loss: 0.3673 - accuracy: 0.8559 - AUC: 0.7448 - val_loss: 0.3746 - val_accuracy: 0.8566 - val_AUC: 0.7349\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3619 - accuracy: 0.8581 - AUC: 0.7546 - val_loss: 0.3708 - val_accuracy: 0.8566 - val_AUC: 0.7323\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 54us/sample - loss: 0.3604 - accuracy: 0.8580 - AUC: 0.7587 - val_loss: 0.3673 - val_accuracy: 0.8569 - val_AUC: 0.7375\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 54us/sample - loss: 0.3566 - accuracy: 0.8595 - AUC: 0.7657 - val_loss: 0.3777 - val_accuracy: 0.8562 - val_AUC: 0.7323\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3536 - accuracy: 0.8593 - AUC: 0.7715 - val_loss: 0.3845 - val_accuracy: 0.8558 - val_AUC: 0.7135\n",
      "5120/5120 [==============================] - 0s 62us/sample - loss: 0.3566 - accuracy: 0.8615 - AUC: 0.7616\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 89us/sample - loss: 0.3987 - accuracy: 0.8533 - AUC: 0.6512 - val_loss: 0.3907 - val_accuracy: 0.8548 - val_AUC: 0.7106\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3742 - accuracy: 0.8546 - AUC: 0.7267 - val_loss: 0.3808 - val_accuracy: 0.8511 - val_AUC: 0.7230\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3672 - accuracy: 0.8556 - AUC: 0.7410 - val_loss: 0.3698 - val_accuracy: 0.8567 - val_AUC: 0.7307\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3635 - accuracy: 0.8563 - AUC: 0.7489 - val_loss: 0.3718 - val_accuracy: 0.8536 - val_AUC: 0.7318\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3596 - accuracy: 0.8577 - AUC: 0.7566 - val_loss: 0.3685 - val_accuracy: 0.8530 - val_AUC: 0.7367\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 54us/sample - loss: 0.3561 - accuracy: 0.8608 - AUC: 0.7612 - val_loss: 0.3696 - val_accuracy: 0.8553 - val_AUC: 0.7354\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 54us/sample - loss: 0.3518 - accuracy: 0.8610 - AUC: 0.7704 - val_loss: 0.3787 - val_accuracy: 0.8514 - val_AUC: 0.7312\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 54us/sample - loss: 0.3487 - accuracy: 0.8641 - AUC: 0.7755 - val_loss: 0.3755 - val_accuracy: 0.8531 - val_AUC: 0.7304\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 54us/sample - loss: 0.3434 - accuracy: 0.8647 - AUC: 0.7843 - val_loss: 0.3790 - val_accuracy: 0.8492 - val_AUC: 0.7314\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3402 - accuracy: 0.8656 - AUC: 0.7900 - val_loss: 0.3844 - val_accuracy: 0.8500 - val_AUC: 0.7209\n",
      "5120/5120 [==============================] - 0s 61us/sample - loss: 0.3720 - accuracy: 0.8518 - AUC: 0.7433\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 104us/sample - loss: 0.4005 - accuracy: 0.8513 - AUC: 0.6530 - val_loss: 0.3773 - val_accuracy: 0.8564 - val_AUC: 0.7116\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3785 - accuracy: 0.8518 - AUC: 0.7222 - val_loss: 0.3709 - val_accuracy: 0.8566 - val_AUC: 0.7286\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3692 - accuracy: 0.8546 - AUC: 0.7414 - val_loss: 0.3694 - val_accuracy: 0.8564 - val_AUC: 0.7337\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3663 - accuracy: 0.8562 - AUC: 0.7484 - val_loss: 0.3799 - val_accuracy: 0.8578 - val_AUC: 0.7333\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3619 - accuracy: 0.8569 - AUC: 0.7564 - val_loss: 0.3692 - val_accuracy: 0.8561 - val_AUC: 0.7342\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3576 - accuracy: 0.8576 - AUC: 0.7644 - val_loss: 0.3703 - val_accuracy: 0.8586 - val_AUC: 0.7341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3545 - accuracy: 0.8589 - AUC: 0.7713 - val_loss: 0.3723 - val_accuracy: 0.8572 - val_AUC: 0.7291\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3514 - accuracy: 0.8610 - AUC: 0.7749 - val_loss: 0.3711 - val_accuracy: 0.8562 - val_AUC: 0.7308\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3459 - accuracy: 0.8629 - AUC: 0.7841 - val_loss: 0.3763 - val_accuracy: 0.8556 - val_AUC: 0.7262\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3419 - accuracy: 0.8638 - AUC: 0.7919 - val_loss: 0.3912 - val_accuracy: 0.8573 - val_AUC: 0.7262\n",
      "5120/5120 [==============================] - 0s 67us/sample - loss: 0.3639 - accuracy: 0.8578 - AUC: 0.7426\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 99us/sample - loss: 0.4027 - accuracy: 0.8518 - AUC: 0.6426 - val_loss: 0.3828 - val_accuracy: 0.8550 - val_AUC: 0.7184\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3744 - accuracy: 0.8553 - AUC: 0.7253 - val_loss: 0.3734 - val_accuracy: 0.8556 - val_AUC: 0.7333\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3674 - accuracy: 0.8567 - AUC: 0.7408 - val_loss: 0.3753 - val_accuracy: 0.8511 - val_AUC: 0.7280\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3623 - accuracy: 0.8566 - AUC: 0.7515 - val_loss: 0.3721 - val_accuracy: 0.8562 - val_AUC: 0.7264\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3574 - accuracy: 0.8591 - AUC: 0.7613 - val_loss: 0.3720 - val_accuracy: 0.8537 - val_AUC: 0.7305\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3551 - accuracy: 0.8598 - AUC: 0.7664 - val_loss: 0.3765 - val_accuracy: 0.8561 - val_AUC: 0.7316\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3513 - accuracy: 0.8606 - AUC: 0.7735 - val_loss: 0.3810 - val_accuracy: 0.8439 - val_AUC: 0.7304\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3474 - accuracy: 0.8616 - AUC: 0.7816 - val_loss: 0.3778 - val_accuracy: 0.8556 - val_AUC: 0.7311\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3418 - accuracy: 0.8646 - AUC: 0.7899 - val_loss: 0.3834 - val_accuracy: 0.8481 - val_AUC: 0.7191\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3365 - accuracy: 0.8669 - AUC: 0.7967 - val_loss: 0.3842 - val_accuracy: 0.8458 - val_AUC: 0.7249\n",
      "5120/5120 [==============================] - 0s 63us/sample - loss: 0.3725 - accuracy: 0.8568 - AUC: 0.7345\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 90us/sample - loss: 0.4001 - accuracy: 0.8537 - AUC: 0.6469 - val_loss: 0.3763 - val_accuracy: 0.8547 - val_AUC: 0.7183\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3767 - accuracy: 0.8544 - AUC: 0.7190 - val_loss: 0.3703 - val_accuracy: 0.8544 - val_AUC: 0.7325\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3688 - accuracy: 0.8577 - AUC: 0.7346 - val_loss: 0.3732 - val_accuracy: 0.8530 - val_AUC: 0.7388\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3645 - accuracy: 0.8576 - AUC: 0.7446 - val_loss: 0.3662 - val_accuracy: 0.8541 - val_AUC: 0.7430\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3586 - accuracy: 0.8585 - AUC: 0.7578 - val_loss: 0.3832 - val_accuracy: 0.8422 - val_AUC: 0.7360\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3543 - accuracy: 0.8609 - AUC: 0.7655 - val_loss: 0.3725 - val_accuracy: 0.8553 - val_AUC: 0.7336\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3528 - accuracy: 0.8605 - AUC: 0.7676 - val_loss: 0.3762 - val_accuracy: 0.8570 - val_AUC: 0.7329\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3463 - accuracy: 0.8625 - AUC: 0.7804 - val_loss: 0.3785 - val_accuracy: 0.8547 - val_AUC: 0.7235\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3434 - accuracy: 0.8639 - AUC: 0.7857 - val_loss: 0.3754 - val_accuracy: 0.8550 - val_AUC: 0.7257\n",
      "5120/5120 [==============================] - 0s 61us/sample - loss: 0.3677 - accuracy: 0.8533 - AUC: 0.7531\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 90us/sample - loss: 0.4023 - accuracy: 0.8521 - AUC: 0.6461 - val_loss: 0.3782 - val_accuracy: 0.8548 - val_AUC: 0.7115\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3799 - accuracy: 0.8536 - AUC: 0.7157 - val_loss: 0.3716 - val_accuracy: 0.8564 - val_AUC: 0.7267\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3692 - accuracy: 0.8561 - AUC: 0.7376 - val_loss: 0.3821 - val_accuracy: 0.8561 - val_AUC: 0.7332\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3652 - accuracy: 0.8567 - AUC: 0.7481 - val_loss: 0.3857 - val_accuracy: 0.8573 - val_AUC: 0.7283\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3623 - accuracy: 0.8581 - AUC: 0.7536 - val_loss: 0.3702 - val_accuracy: 0.8566 - val_AUC: 0.7345\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3584 - accuracy: 0.8595 - AUC: 0.7604 - val_loss: 0.3713 - val_accuracy: 0.8562 - val_AUC: 0.7311\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3546 - accuracy: 0.8586 - AUC: 0.7693 - val_loss: 0.3760 - val_accuracy: 0.8545 - val_AUC: 0.7306\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3492 - accuracy: 0.8612 - AUC: 0.7786 - val_loss: 0.3773 - val_accuracy: 0.8562 - val_AUC: 0.7199\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3430 - accuracy: 0.8635 - AUC: 0.7901 - val_loss: 0.3844 - val_accuracy: 0.8509 - val_AUC: 0.7134\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3383 - accuracy: 0.8657 - AUC: 0.7951 - val_loss: 0.3853 - val_accuracy: 0.8517 - val_AUC: 0.7087\n",
      "5120/5120 [==============================] - 0s 72us/sample - loss: 0.3616 - accuracy: 0.8559 - AUC: 0.7552\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 106us/sample - loss: 0.3982 - accuracy: 0.8532 - AUC: 0.6529 - val_loss: 0.3788 - val_accuracy: 0.8562 - val_AUC: 0.7184\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 67us/sample - loss: 0.3753 - accuracy: 0.8542 - AUC: 0.7207 - val_loss: 0.3686 - val_accuracy: 0.8566 - val_AUC: 0.7388\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3671 - accuracy: 0.8562 - AUC: 0.7431 - val_loss: 0.3777 - val_accuracy: 0.8566 - val_AUC: 0.7272\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 69us/sample - loss: 0.3616 - accuracy: 0.8569 - AUC: 0.7532 - val_loss: 0.3675 - val_accuracy: 0.8566 - val_AUC: 0.7350\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3566 - accuracy: 0.8596 - AUC: 0.7628 - val_loss: 0.3723 - val_accuracy: 0.8537 - val_AUC: 0.7320\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 68us/sample - loss: 0.3519 - accuracy: 0.8609 - AUC: 0.7714 - val_loss: 0.3735 - val_accuracy: 0.8531 - val_AUC: 0.7340\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3483 - accuracy: 0.8618 - AUC: 0.7790 - val_loss: 0.3726 - val_accuracy: 0.8559 - val_AUC: 0.7403\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3433 - accuracy: 0.8637 - AUC: 0.7858 - val_loss: 0.3782 - val_accuracy: 0.8550 - val_AUC: 0.7291\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 67us/sample - loss: 0.3388 - accuracy: 0.8643 - AUC: 0.7943 - val_loss: 0.3749 - val_accuracy: 0.8555 - val_AUC: 0.7304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5120/5120 [==============================] - 0s 67us/sample - loss: 0.3726 - accuracy: 0.8531 - AUC: 0.7376\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 97us/sample - loss: 0.4030 - accuracy: 0.8508 - AUC: 0.6463 - val_loss: 0.3992 - val_accuracy: 0.8548 - val_AUC: 0.7176\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3787 - accuracy: 0.8536 - AUC: 0.7190 - val_loss: 0.3706 - val_accuracy: 0.8570 - val_AUC: 0.7317\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 67us/sample - loss: 0.3678 - accuracy: 0.8553 - AUC: 0.7444 - val_loss: 0.3727 - val_accuracy: 0.8545 - val_AUC: 0.7251\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3649 - accuracy: 0.8560 - AUC: 0.7508 - val_loss: 0.3690 - val_accuracy: 0.8562 - val_AUC: 0.7325\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3605 - accuracy: 0.8578 - AUC: 0.7589 - val_loss: 0.3708 - val_accuracy: 0.8566 - val_AUC: 0.7332\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3564 - accuracy: 0.8588 - AUC: 0.7661 - val_loss: 0.3756 - val_accuracy: 0.8486 - val_AUC: 0.7284\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3530 - accuracy: 0.8607 - AUC: 0.7725 - val_loss: 0.3812 - val_accuracy: 0.8489 - val_AUC: 0.7289\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3490 - accuracy: 0.8600 - AUC: 0.7796 - val_loss: 0.3784 - val_accuracy: 0.8577 - val_AUC: 0.7195\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3425 - accuracy: 0.8625 - AUC: 0.7913 - val_loss: 0.3827 - val_accuracy: 0.8520 - val_AUC: 0.7179\n",
      "5120/5120 [==============================] - 0s 64us/sample - loss: 0.3591 - accuracy: 0.8607 - AUC: 0.7499\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 102us/sample - loss: 0.3991 - accuracy: 0.8530 - AUC: 0.6510 - val_loss: 0.3802 - val_accuracy: 0.8552 - val_AUC: 0.7153\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3766 - accuracy: 0.8548 - AUC: 0.7197 - val_loss: 0.3745 - val_accuracy: 0.8519 - val_AUC: 0.7283\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3667 - accuracy: 0.8561 - AUC: 0.7440 - val_loss: 0.3734 - val_accuracy: 0.8534 - val_AUC: 0.7244\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3623 - accuracy: 0.8585 - AUC: 0.7529 - val_loss: 0.3695 - val_accuracy: 0.8542 - val_AUC: 0.7343\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3565 - accuracy: 0.8582 - AUC: 0.7645 - val_loss: 0.3731 - val_accuracy: 0.8536 - val_AUC: 0.7272\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3555 - accuracy: 0.8595 - AUC: 0.7656 - val_loss: 0.3722 - val_accuracy: 0.8552 - val_AUC: 0.7290\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3517 - accuracy: 0.8598 - AUC: 0.7728 - val_loss: 0.3726 - val_accuracy: 0.8536 - val_AUC: 0.7294\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3454 - accuracy: 0.8617 - AUC: 0.7834 - val_loss: 0.3936 - val_accuracy: 0.8403 - val_AUC: 0.7217\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3427 - accuracy: 0.8639 - AUC: 0.7871 - val_loss: 0.3845 - val_accuracy: 0.8502 - val_AUC: 0.7184\n",
      "5120/5120 [==============================] - 0s 74us/sample - loss: 0.3686 - accuracy: 0.8568 - AUC: 0.7413\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 101us/sample - loss: 0.3959 - accuracy: 0.8537 - AUC: 0.6604 - val_loss: 0.3753 - val_accuracy: 0.8562 - val_AUC: 0.7198\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 67us/sample - loss: 0.3756 - accuracy: 0.8547 - AUC: 0.7197 - val_loss: 0.3743 - val_accuracy: 0.8544 - val_AUC: 0.7252\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3677 - accuracy: 0.8564 - AUC: 0.7390 - val_loss: 0.3706 - val_accuracy: 0.8566 - val_AUC: 0.7311\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3626 - accuracy: 0.8574 - AUC: 0.7500 - val_loss: 0.3860 - val_accuracy: 0.8550 - val_AUC: 0.7363\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3586 - accuracy: 0.8595 - AUC: 0.7577 - val_loss: 0.3719 - val_accuracy: 0.8570 - val_AUC: 0.7351\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 68us/sample - loss: 0.3550 - accuracy: 0.8592 - AUC: 0.7660 - val_loss: 0.3729 - val_accuracy: 0.8527 - val_AUC: 0.7308\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 67us/sample - loss: 0.3507 - accuracy: 0.8633 - AUC: 0.7710 - val_loss: 0.3732 - val_accuracy: 0.8536 - val_AUC: 0.7290\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3462 - accuracy: 0.8626 - AUC: 0.7796 - val_loss: 0.3739 - val_accuracy: 0.8541 - val_AUC: 0.7244\n",
      "5120/5120 [==============================] - 0s 69us/sample - loss: 0.3732 - accuracy: 0.8518 - AUC: 0.7439\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 101us/sample - loss: 0.4050 - accuracy: 0.8510 - AUC: 0.6394 - val_loss: 0.3862 - val_accuracy: 0.8550 - val_AUC: 0.7072\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3795 - accuracy: 0.8539 - AUC: 0.7158 - val_loss: 0.3733 - val_accuracy: 0.8575 - val_AUC: 0.7304\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3715 - accuracy: 0.8542 - AUC: 0.7358 - val_loss: 0.3682 - val_accuracy: 0.8573 - val_AUC: 0.7325\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3643 - accuracy: 0.8564 - AUC: 0.7509 - val_loss: 0.3727 - val_accuracy: 0.8553 - val_AUC: 0.7261\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3602 - accuracy: 0.8575 - AUC: 0.7591 - val_loss: 0.3700 - val_accuracy: 0.8553 - val_AUC: 0.7302\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3552 - accuracy: 0.8594 - AUC: 0.7677 - val_loss: 0.3721 - val_accuracy: 0.8555 - val_AUC: 0.7289\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3538 - accuracy: 0.8604 - AUC: 0.7709 - val_loss: 0.3818 - val_accuracy: 0.8561 - val_AUC: 0.7244\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3456 - accuracy: 0.8636 - AUC: 0.7857 - val_loss: 0.3822 - val_accuracy: 0.8506 - val_AUC: 0.7076\n",
      "5120/5120 [==============================] - 0s 68us/sample - loss: 0.3617 - accuracy: 0.8561 - AUC: 0.7523\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 97us/sample - loss: 0.3977 - accuracy: 0.8534 - AUC: 0.6528 - val_loss: 0.3771 - val_accuracy: 0.8550 - val_AUC: 0.7142\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3758 - accuracy: 0.8542 - AUC: 0.7211 - val_loss: 0.3693 - val_accuracy: 0.8561 - val_AUC: 0.7342\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3674 - accuracy: 0.8558 - AUC: 0.7399 - val_loss: 0.3670 - val_accuracy: 0.8559 - val_AUC: 0.7362\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3629 - accuracy: 0.8576 - AUC: 0.7504 - val_loss: 0.3670 - val_accuracy: 0.8575 - val_AUC: 0.7389\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3581 - accuracy: 0.8589 - AUC: 0.7585 - val_loss: 0.3736 - val_accuracy: 0.8497 - val_AUC: 0.7333\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3542 - accuracy: 0.8605 - AUC: 0.7669 - val_loss: 0.3769 - val_accuracy: 0.8559 - val_AUC: 0.7338\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3493 - accuracy: 0.8611 - AUC: 0.7755 - val_loss: 0.4034 - val_accuracy: 0.8309 - val_AUC: 0.7163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3466 - accuracy: 0.8638 - AUC: 0.7786 - val_loss: 0.3760 - val_accuracy: 0.8544 - val_AUC: 0.7261\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3416 - accuracy: 0.8653 - AUC: 0.7855 - val_loss: 0.3772 - val_accuracy: 0.8561 - val_AUC: 0.7320\n",
      "5120/5120 [==============================] - 0s 69us/sample - loss: 0.3743 - accuracy: 0.8504 - AUC: 0.7416\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 100us/sample - loss: 0.4051 - accuracy: 0.8519 - AUC: 0.6381 - val_loss: 0.3761 - val_accuracy: 0.8548 - val_AUC: 0.7184\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3794 - accuracy: 0.8526 - AUC: 0.7177 - val_loss: 0.3845 - val_accuracy: 0.8559 - val_AUC: 0.7373\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3703 - accuracy: 0.8540 - AUC: 0.7393 - val_loss: 0.3697 - val_accuracy: 0.8567 - val_AUC: 0.7318\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3668 - accuracy: 0.8560 - AUC: 0.7458 - val_loss: 0.3918 - val_accuracy: 0.8475 - val_AUC: 0.7356\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3617 - accuracy: 0.8566 - AUC: 0.7563 - val_loss: 0.3784 - val_accuracy: 0.8577 - val_AUC: 0.7324\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3565 - accuracy: 0.8585 - AUC: 0.7665 - val_loss: 0.3744 - val_accuracy: 0.8562 - val_AUC: 0.7376\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3525 - accuracy: 0.8601 - AUC: 0.7734 - val_loss: 0.3702 - val_accuracy: 0.8572 - val_AUC: 0.7281\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3474 - accuracy: 0.8623 - AUC: 0.7814 - val_loss: 0.3741 - val_accuracy: 0.8577 - val_AUC: 0.7347\n",
      "5120/5120 [==============================] - 0s 65us/sample - loss: 0.3616 - accuracy: 0.8584 - AUC: 0.7421\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 94us/sample - loss: 0.4004 - accuracy: 0.8531 - AUC: 0.6479 - val_loss: 0.3790 - val_accuracy: 0.8552 - val_AUC: 0.7165\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3764 - accuracy: 0.8544 - AUC: 0.7195 - val_loss: 0.3724 - val_accuracy: 0.8533 - val_AUC: 0.7326\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3677 - accuracy: 0.8563 - AUC: 0.7417 - val_loss: 0.3811 - val_accuracy: 0.8517 - val_AUC: 0.7357\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3609 - accuracy: 0.8574 - AUC: 0.7550 - val_loss: 0.3897 - val_accuracy: 0.8547 - val_AUC: 0.7322\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3585 - accuracy: 0.8590 - AUC: 0.7586 - val_loss: 0.3739 - val_accuracy: 0.8547 - val_AUC: 0.7356\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3531 - accuracy: 0.8613 - AUC: 0.7685 - val_loss: 0.3736 - val_accuracy: 0.8533 - val_AUC: 0.7298\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3479 - accuracy: 0.8610 - AUC: 0.7783 - val_loss: 0.3762 - val_accuracy: 0.8516 - val_AUC: 0.7226\n",
      "5120/5120 [==============================] - 0s 69us/sample - loss: 0.3773 - accuracy: 0.8531 - AUC: 0.7268\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 107us/sample - loss: 0.3998 - accuracy: 0.8518 - AUC: 0.6483 - val_loss: 0.3771 - val_accuracy: 0.8567 - val_AUC: 0.7183\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3762 - accuracy: 0.8548 - AUC: 0.7203 - val_loss: 0.3695 - val_accuracy: 0.8566 - val_AUC: 0.7319\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3666 - accuracy: 0.8574 - AUC: 0.7394 - val_loss: 0.3705 - val_accuracy: 0.8533 - val_AUC: 0.7316\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3616 - accuracy: 0.8596 - AUC: 0.7509 - val_loss: 0.3713 - val_accuracy: 0.8527 - val_AUC: 0.7319\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3581 - accuracy: 0.8588 - AUC: 0.7578 - val_loss: 0.3688 - val_accuracy: 0.8572 - val_AUC: 0.7317\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3522 - accuracy: 0.8603 - AUC: 0.7705 - val_loss: 0.3783 - val_accuracy: 0.8569 - val_AUC: 0.7305\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3498 - accuracy: 0.8616 - AUC: 0.7743 - val_loss: 0.3787 - val_accuracy: 0.8516 - val_AUC: 0.7234\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3433 - accuracy: 0.8640 - AUC: 0.7850 - val_loss: 0.3794 - val_accuracy: 0.8536 - val_AUC: 0.7167\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3374 - accuracy: 0.8666 - AUC: 0.7954 - val_loss: 0.3839 - val_accuracy: 0.8508 - val_AUC: 0.7087\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3331 - accuracy: 0.8669 - AUC: 0.8023 - val_loss: 0.3914 - val_accuracy: 0.8514 - val_AUC: 0.7083\n",
      "5120/5120 [==============================] - 0s 64us/sample - loss: 0.3735 - accuracy: 0.8531 - AUC: 0.7421\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 90us/sample - loss: 0.4054 - accuracy: 0.8518 - AUC: 0.6334 - val_loss: 0.3929 - val_accuracy: 0.8547 - val_AUC: 0.7132\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3816 - accuracy: 0.8536 - AUC: 0.7092 - val_loss: 0.3749 - val_accuracy: 0.8537 - val_AUC: 0.7273\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3701 - accuracy: 0.8563 - AUC: 0.7349 - val_loss: 0.3790 - val_accuracy: 0.8527 - val_AUC: 0.7382\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3647 - accuracy: 0.8564 - AUC: 0.7488 - val_loss: 0.3777 - val_accuracy: 0.8486 - val_AUC: 0.7302\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3600 - accuracy: 0.8582 - AUC: 0.7585 - val_loss: 0.3732 - val_accuracy: 0.8564 - val_AUC: 0.7320\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3571 - accuracy: 0.8589 - AUC: 0.7641 - val_loss: 0.3803 - val_accuracy: 0.8484 - val_AUC: 0.7304\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3529 - accuracy: 0.8597 - AUC: 0.7709 - val_loss: 0.3734 - val_accuracy: 0.8544 - val_AUC: 0.7271\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3475 - accuracy: 0.8628 - AUC: 0.7801 - val_loss: 0.3804 - val_accuracy: 0.8514 - val_AUC: 0.7213\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3448 - accuracy: 0.8621 - AUC: 0.7863 - val_loss: 0.3785 - val_accuracy: 0.8480 - val_AUC: 0.7294\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3390 - accuracy: 0.8656 - AUC: 0.7946 - val_loss: 0.3841 - val_accuracy: 0.8417 - val_AUC: 0.7234\n",
      "5120/5120 [==============================] - 0s 63us/sample - loss: 0.3648 - accuracy: 0.8578 - AUC: 0.7552\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 95us/sample - loss: 0.4047 - accuracy: 0.8517 - AUC: 0.6294 - val_loss: 0.3796 - val_accuracy: 0.8545 - val_AUC: 0.7125\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3753 - accuracy: 0.8543 - AUC: 0.7214 - val_loss: 0.3748 - val_accuracy: 0.8555 - val_AUC: 0.7345\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3681 - accuracy: 0.8563 - AUC: 0.7381 - val_loss: 0.3877 - val_accuracy: 0.8505 - val_AUC: 0.7367\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3622 - accuracy: 0.8587 - AUC: 0.7502 - val_loss: 0.3652 - val_accuracy: 0.8586 - val_AUC: 0.7407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3596 - accuracy: 0.8581 - AUC: 0.7560 - val_loss: 0.3744 - val_accuracy: 0.8570 - val_AUC: 0.7389\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3543 - accuracy: 0.8608 - AUC: 0.7652 - val_loss: 0.3750 - val_accuracy: 0.8528 - val_AUC: 0.7327\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3497 - accuracy: 0.8620 - AUC: 0.7749 - val_loss: 0.3716 - val_accuracy: 0.8552 - val_AUC: 0.7337\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3457 - accuracy: 0.8643 - AUC: 0.7802 - val_loss: 0.3795 - val_accuracy: 0.8581 - val_AUC: 0.7291\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3430 - accuracy: 0.8651 - AUC: 0.7864 - val_loss: 0.3734 - val_accuracy: 0.8506 - val_AUC: 0.7342\n",
      "5120/5120 [==============================] - 0s 69us/sample - loss: 0.3733 - accuracy: 0.8521 - AUC: 0.7422\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 92us/sample - loss: 0.4006 - accuracy: 0.8521 - AUC: 0.6504 - val_loss: 0.3838 - val_accuracy: 0.8555 - val_AUC: 0.7126\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3762 - accuracy: 0.8522 - AUC: 0.7264 - val_loss: 0.3764 - val_accuracy: 0.8550 - val_AUC: 0.7267\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3686 - accuracy: 0.8547 - AUC: 0.7435 - val_loss: 0.3815 - val_accuracy: 0.8566 - val_AUC: 0.7340\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3647 - accuracy: 0.8569 - AUC: 0.7497 - val_loss: 0.3677 - val_accuracy: 0.8558 - val_AUC: 0.7364\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3626 - accuracy: 0.8557 - AUC: 0.7558 - val_loss: 0.3763 - val_accuracy: 0.8555 - val_AUC: 0.7364\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3580 - accuracy: 0.8569 - AUC: 0.7650 - val_loss: 0.3671 - val_accuracy: 0.8570 - val_AUC: 0.7355\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3531 - accuracy: 0.8603 - AUC: 0.7723 - val_loss: 0.3692 - val_accuracy: 0.8564 - val_AUC: 0.7351\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 57us/sample - loss: 0.3499 - accuracy: 0.8612 - AUC: 0.7789 - val_loss: 0.3751 - val_accuracy: 0.8542 - val_AUC: 0.7266\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3442 - accuracy: 0.8631 - AUC: 0.7886 - val_loss: 0.4044 - val_accuracy: 0.8570 - val_AUC: 0.7298\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3408 - accuracy: 0.8646 - AUC: 0.7941 - val_loss: 0.3800 - val_accuracy: 0.8548 - val_AUC: 0.7229\n",
      "Epoch 11/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3354 - accuracy: 0.8663 - AUC: 0.8025 - val_loss: 0.3892 - val_accuracy: 0.8548 - val_AUC: 0.7132\n",
      "5120/5120 [==============================] - 0s 70us/sample - loss: 0.3608 - accuracy: 0.8572 - AUC: 0.7476\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 114us/sample - loss: 0.4047 - accuracy: 0.8522 - AUC: 0.6297 - val_loss: 0.3835 - val_accuracy: 0.8547 - val_AUC: 0.7048\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3777 - accuracy: 0.8550 - AUC: 0.7161 - val_loss: 0.3719 - val_accuracy: 0.8569 - val_AUC: 0.7290\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3674 - accuracy: 0.8552 - AUC: 0.7409 - val_loss: 0.3776 - val_accuracy: 0.8506 - val_AUC: 0.7236\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3618 - accuracy: 0.8560 - AUC: 0.7540 - val_loss: 0.3762 - val_accuracy: 0.8552 - val_AUC: 0.7333\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3585 - accuracy: 0.8581 - AUC: 0.7605 - val_loss: 0.3741 - val_accuracy: 0.8562 - val_AUC: 0.7334\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3525 - accuracy: 0.8610 - AUC: 0.7704 - val_loss: 0.3769 - val_accuracy: 0.8550 - val_AUC: 0.7303\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3506 - accuracy: 0.8626 - AUC: 0.7717 - val_loss: 0.3779 - val_accuracy: 0.8525 - val_AUC: 0.7272\n",
      "5120/5120 [==============================] - 0s 63us/sample - loss: 0.3747 - accuracy: 0.8535 - AUC: 0.7284\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 98us/sample - loss: 0.3990 - accuracy: 0.8534 - AUC: 0.6468 - val_loss: 0.3789 - val_accuracy: 0.8545 - val_AUC: 0.7150\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3740 - accuracy: 0.8552 - AUC: 0.7231 - val_loss: 0.3709 - val_accuracy: 0.8555 - val_AUC: 0.7334\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3680 - accuracy: 0.8572 - AUC: 0.7375 - val_loss: 0.3685 - val_accuracy: 0.8567 - val_AUC: 0.7357\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3636 - accuracy: 0.8597 - AUC: 0.7454 - val_loss: 0.3675 - val_accuracy: 0.8566 - val_AUC: 0.7390\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3595 - accuracy: 0.8596 - AUC: 0.7559 - val_loss: 0.3679 - val_accuracy: 0.8580 - val_AUC: 0.7361\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3550 - accuracy: 0.8610 - AUC: 0.7638 - val_loss: 0.3694 - val_accuracy: 0.8578 - val_AUC: 0.7325\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3517 - accuracy: 0.8620 - AUC: 0.7703 - val_loss: 0.3818 - val_accuracy: 0.8500 - val_AUC: 0.7293\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3471 - accuracy: 0.8657 - AUC: 0.7759 - val_loss: 0.3742 - val_accuracy: 0.8544 - val_AUC: 0.7312\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3418 - accuracy: 0.8646 - AUC: 0.7874 - val_loss: 0.3803 - val_accuracy: 0.8519 - val_AUC: 0.7166\n",
      "5120/5120 [==============================] - 0s 64us/sample - loss: 0.3727 - accuracy: 0.8518 - AUC: 0.7474\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 89us/sample - loss: 0.4050 - accuracy: 0.8519 - AUC: 0.6322 - val_loss: 0.3797 - val_accuracy: 0.8548 - val_AUC: 0.7156\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3797 - accuracy: 0.8527 - AUC: 0.7168 - val_loss: 0.3741 - val_accuracy: 0.8553 - val_AUC: 0.7311\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3701 - accuracy: 0.8561 - AUC: 0.7363 - val_loss: 0.3693 - val_accuracy: 0.8552 - val_AUC: 0.7325\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3652 - accuracy: 0.8562 - AUC: 0.7486 - val_loss: 0.3747 - val_accuracy: 0.8547 - val_AUC: 0.7378\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3613 - accuracy: 0.8569 - AUC: 0.7552 - val_loss: 0.3738 - val_accuracy: 0.8566 - val_AUC: 0.7251\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3572 - accuracy: 0.8593 - AUC: 0.7639 - val_loss: 0.3738 - val_accuracy: 0.8550 - val_AUC: 0.7341\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3529 - accuracy: 0.8599 - AUC: 0.7707 - val_loss: 0.3724 - val_accuracy: 0.8556 - val_AUC: 0.7306\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3493 - accuracy: 0.8628 - AUC: 0.7771 - val_loss: 0.3810 - val_accuracy: 0.8536 - val_AUC: 0.7237\n",
      "5120/5120 [==============================] - 0s 67us/sample - loss: 0.3620 - accuracy: 0.8566 - AUC: 0.7509\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 100us/sample - loss: 0.3992 - accuracy: 0.8527 - AUC: 0.6486 - val_loss: 0.3721 - val_accuracy: 0.8556 - val_AUC: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3753 - accuracy: 0.8542 - AUC: 0.7225 - val_loss: 0.3779 - val_accuracy: 0.8556 - val_AUC: 0.7321\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3668 - accuracy: 0.8559 - AUC: 0.7417 - val_loss: 0.3765 - val_accuracy: 0.8536 - val_AUC: 0.7383\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3639 - accuracy: 0.8573 - AUC: 0.7458 - val_loss: 0.3662 - val_accuracy: 0.8578 - val_AUC: 0.7422\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3608 - accuracy: 0.8581 - AUC: 0.7538 - val_loss: 0.3735 - val_accuracy: 0.8481 - val_AUC: 0.7344\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3563 - accuracy: 0.8599 - AUC: 0.7615 - val_loss: 0.3728 - val_accuracy: 0.8550 - val_AUC: 0.7330\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3526 - accuracy: 0.8610 - AUC: 0.7679 - val_loss: 0.3693 - val_accuracy: 0.8564 - val_AUC: 0.7354\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3477 - accuracy: 0.8634 - AUC: 0.7768 - val_loss: 0.3737 - val_accuracy: 0.8522 - val_AUC: 0.7355\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 59us/sample - loss: 0.3440 - accuracy: 0.8650 - AUC: 0.7831 - val_loss: 0.3735 - val_accuracy: 0.8534 - val_AUC: 0.7285\n",
      "5120/5120 [==============================] - 0s 66us/sample - loss: 0.3748 - accuracy: 0.8529 - AUC: 0.7392\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 102us/sample - loss: 0.4001 - accuracy: 0.8523 - AUC: 0.6549 - val_loss: 0.3808 - val_accuracy: 0.8544 - val_AUC: 0.7093\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3767 - accuracy: 0.8541 - AUC: 0.7226 - val_loss: 0.3747 - val_accuracy: 0.8536 - val_AUC: 0.7241\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 55us/sample - loss: 0.3702 - accuracy: 0.8544 - AUC: 0.7384 - val_loss: 0.3801 - val_accuracy: 0.8558 - val_AUC: 0.7343\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 56us/sample - loss: 0.3640 - accuracy: 0.8570 - AUC: 0.7518 - val_loss: 0.3697 - val_accuracy: 0.8545 - val_AUC: 0.7337\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 58us/sample - loss: 0.3624 - accuracy: 0.8568 - AUC: 0.7539 - val_loss: 0.3776 - val_accuracy: 0.8491 - val_AUC: 0.7324\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3573 - accuracy: 0.8596 - AUC: 0.7633 - val_loss: 0.3732 - val_accuracy: 0.8556 - val_AUC: 0.7325\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3552 - accuracy: 0.8581 - AUC: 0.7685 - val_loss: 0.3879 - val_accuracy: 0.8398 - val_AUC: 0.7266\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3519 - accuracy: 0.8606 - AUC: 0.7728 - val_loss: 0.3789 - val_accuracy: 0.8500 - val_AUC: 0.7271\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3459 - accuracy: 0.8638 - AUC: 0.7823 - val_loss: 0.3807 - val_accuracy: 0.8531 - val_AUC: 0.7201\n",
      "5120/5120 [==============================] - 0s 66us/sample - loss: 0.3599 - accuracy: 0.8607 - AUC: 0.7480\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 100us/sample - loss: 0.3977 - accuracy: 0.8530 - AUC: 0.6571 - val_loss: 0.3984 - val_accuracy: 0.8550 - val_AUC: 0.7119\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 67us/sample - loss: 0.3769 - accuracy: 0.8549 - AUC: 0.7204 - val_loss: 0.3846 - val_accuracy: 0.8494 - val_AUC: 0.7255\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3677 - accuracy: 0.8567 - AUC: 0.7410 - val_loss: 0.3744 - val_accuracy: 0.8542 - val_AUC: 0.7262\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3624 - accuracy: 0.8575 - AUC: 0.7540 - val_loss: 0.3718 - val_accuracy: 0.8537 - val_AUC: 0.7278\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3584 - accuracy: 0.8592 - AUC: 0.7611 - val_loss: 0.3721 - val_accuracy: 0.8555 - val_AUC: 0.7291\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3558 - accuracy: 0.8603 - AUC: 0.7650 - val_loss: 0.3717 - val_accuracy: 0.8537 - val_AUC: 0.7326\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 68us/sample - loss: 0.3515 - accuracy: 0.8594 - AUC: 0.7732 - val_loss: 0.3823 - val_accuracy: 0.8495 - val_AUC: 0.7227\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 69us/sample - loss: 0.3473 - accuracy: 0.8622 - AUC: 0.7817 - val_loss: 0.3980 - val_accuracy: 0.8311 - val_AUC: 0.7278\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 69us/sample - loss: 0.3423 - accuracy: 0.8658 - AUC: 0.7875 - val_loss: 0.3861 - val_accuracy: 0.8562 - val_AUC: 0.7226\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 71us/sample - loss: 0.3376 - accuracy: 0.8661 - AUC: 0.7956 - val_loss: 0.3822 - val_accuracy: 0.8530 - val_AUC: 0.7154\n",
      "Epoch 11/20\n",
      "20480/20480 [==============================] - 1s 70us/sample - loss: 0.3313 - accuracy: 0.8672 - AUC: 0.8061 - val_loss: 0.3898 - val_accuracy: 0.8422 - val_AUC: 0.7189\n",
      "5120/5120 [==============================] - 0s 73us/sample - loss: 0.3716 - accuracy: 0.8551 - AUC: 0.7368\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 107us/sample - loss: 0.3997 - accuracy: 0.8536 - AUC: 0.6387 - val_loss: 0.3751 - val_accuracy: 0.8555 - val_AUC: 0.7232\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 68us/sample - loss: 0.3745 - accuracy: 0.8552 - AUC: 0.7232 - val_loss: 0.3776 - val_accuracy: 0.8570 - val_AUC: 0.7340\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3671 - accuracy: 0.8566 - AUC: 0.7403 - val_loss: 0.3708 - val_accuracy: 0.8537 - val_AUC: 0.7367\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3628 - accuracy: 0.8577 - AUC: 0.7483 - val_loss: 0.3708 - val_accuracy: 0.8564 - val_AUC: 0.7349\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3577 - accuracy: 0.8577 - AUC: 0.7606 - val_loss: 0.3724 - val_accuracy: 0.8536 - val_AUC: 0.7307\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 68us/sample - loss: 0.3547 - accuracy: 0.8603 - AUC: 0.7652 - val_loss: 0.3713 - val_accuracy: 0.8564 - val_AUC: 0.7311\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3503 - accuracy: 0.8623 - AUC: 0.7736 - val_loss: 0.3720 - val_accuracy: 0.8530 - val_AUC: 0.7327\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3443 - accuracy: 0.8638 - AUC: 0.7837 - val_loss: 0.3798 - val_accuracy: 0.8497 - val_AUC: 0.7269\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3416 - accuracy: 0.8647 - AUC: 0.7875 - val_loss: 0.3943 - val_accuracy: 0.8352 - val_AUC: 0.7178\n",
      "5120/5120 [==============================] - 0s 68us/sample - loss: 0.3738 - accuracy: 0.8521 - AUC: 0.7467\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 112us/sample - loss: 0.4058 - accuracy: 0.8510 - AUC: 0.6343 - val_loss: 0.3795 - val_accuracy: 0.8555 - val_AUC: 0.7144\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 68us/sample - loss: 0.3803 - accuracy: 0.8535 - AUC: 0.7142 - val_loss: 0.3759 - val_accuracy: 0.8548 - val_AUC: 0.7334\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 67us/sample - loss: 0.3707 - accuracy: 0.8548 - AUC: 0.7368 - val_loss: 0.3658 - val_accuracy: 0.8575 - val_AUC: 0.7419\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 69us/sample - loss: 0.3662 - accuracy: 0.8564 - AUC: 0.7452 - val_loss: 0.3716 - val_accuracy: 0.8567 - val_AUC: 0.7322\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 69us/sample - loss: 0.3611 - accuracy: 0.8580 - AUC: 0.7574 - val_loss: 0.3695 - val_accuracy: 0.8558 - val_AUC: 0.7361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3569 - accuracy: 0.8580 - AUC: 0.7653 - val_loss: 0.3802 - val_accuracy: 0.8561 - val_AUC: 0.7305\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3522 - accuracy: 0.8601 - AUC: 0.7723 - val_loss: 0.3781 - val_accuracy: 0.8553 - val_AUC: 0.7255\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3471 - accuracy: 0.8625 - AUC: 0.7828 - val_loss: 0.3864 - val_accuracy: 0.8491 - val_AUC: 0.7158\n",
      "5120/5120 [==============================] - 0s 67us/sample - loss: 0.3601 - accuracy: 0.8574 - AUC: 0.7551\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 95us/sample - loss: 0.4006 - accuracy: 0.8529 - AUC: 0.6458 - val_loss: 0.3799 - val_accuracy: 0.8545 - val_AUC: 0.7147\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3783 - accuracy: 0.8544 - AUC: 0.7129 - val_loss: 0.3694 - val_accuracy: 0.8573 - val_AUC: 0.7347\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3681 - accuracy: 0.8548 - AUC: 0.7395 - val_loss: 0.3673 - val_accuracy: 0.8572 - val_AUC: 0.7375\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 60us/sample - loss: 0.3627 - accuracy: 0.8578 - AUC: 0.7506 - val_loss: 0.3673 - val_accuracy: 0.8559 - val_AUC: 0.7362\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3573 - accuracy: 0.8603 - AUC: 0.7601 - val_loss: 0.3665 - val_accuracy: 0.8584 - val_AUC: 0.7404\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3531 - accuracy: 0.8597 - AUC: 0.7688 - val_loss: 0.3775 - val_accuracy: 0.8555 - val_AUC: 0.7263\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 73us/sample - loss: 0.3500 - accuracy: 0.8621 - AUC: 0.7737 - val_loss: 0.3739 - val_accuracy: 0.8511 - val_AUC: 0.7309\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 69us/sample - loss: 0.3443 - accuracy: 0.8645 - AUC: 0.7839 - val_loss: 0.3724 - val_accuracy: 0.8550 - val_AUC: 0.7319\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 70us/sample - loss: 0.3386 - accuracy: 0.8660 - AUC: 0.7933 - val_loss: 0.3864 - val_accuracy: 0.8539 - val_AUC: 0.7134\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 68us/sample - loss: 0.3341 - accuracy: 0.8677 - AUC: 0.7998 - val_loss: 0.3797 - val_accuracy: 0.8531 - val_AUC: 0.7248\n",
      "5120/5120 [==============================] - 0s 72us/sample - loss: 0.3755 - accuracy: 0.8508 - AUC: 0.7403\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 119us/sample - loss: 0.4025 - accuracy: 0.8513 - AUC: 0.6477 - val_loss: 0.3805 - val_accuracy: 0.8553 - val_AUC: 0.7151\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 63us/sample - loss: 0.3758 - accuracy: 0.8535 - AUC: 0.7269 - val_loss: 0.3701 - val_accuracy: 0.8558 - val_AUC: 0.7337\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3684 - accuracy: 0.8553 - AUC: 0.7425 - val_loss: 0.3732 - val_accuracy: 0.8556 - val_AUC: 0.7288\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 61us/sample - loss: 0.3636 - accuracy: 0.8559 - AUC: 0.7533 - val_loss: 0.3767 - val_accuracy: 0.8553 - val_AUC: 0.7414\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 67us/sample - loss: 0.3597 - accuracy: 0.8580 - AUC: 0.7600 - val_loss: 0.3721 - val_accuracy: 0.8528 - val_AUC: 0.7346\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3551 - accuracy: 0.8595 - AUC: 0.7690 - val_loss: 0.3706 - val_accuracy: 0.8539 - val_AUC: 0.7312\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3502 - accuracy: 0.8611 - AUC: 0.7786 - val_loss: 0.3724 - val_accuracy: 0.8558 - val_AUC: 0.7297\n",
      "5120/5120 [==============================] - 0s 70us/sample - loss: 0.3642 - accuracy: 0.8584 - AUC: 0.7393\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 100us/sample - loss: 0.4004 - accuracy: 0.8528 - AUC: 0.6457 - val_loss: 0.3777 - val_accuracy: 0.8558 - val_AUC: 0.7140\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3738 - accuracy: 0.8555 - AUC: 0.7262 - val_loss: 0.3706 - val_accuracy: 0.8562 - val_AUC: 0.7339\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3661 - accuracy: 0.8564 - AUC: 0.7440 - val_loss: 0.3758 - val_accuracy: 0.8572 - val_AUC: 0.7331\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3621 - accuracy: 0.8572 - AUC: 0.7533 - val_loss: 0.3734 - val_accuracy: 0.8548 - val_AUC: 0.7350\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 62us/sample - loss: 0.3582 - accuracy: 0.8591 - AUC: 0.7610 - val_loss: 0.3726 - val_accuracy: 0.8516 - val_AUC: 0.7385\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3552 - accuracy: 0.8590 - AUC: 0.7668 - val_loss: 0.3744 - val_accuracy: 0.8525 - val_AUC: 0.7311\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3497 - accuracy: 0.8620 - AUC: 0.7750 - val_loss: 0.3894 - val_accuracy: 0.8369 - val_AUC: 0.7250\n",
      "5120/5120 [==============================] - 0s 69us/sample - loss: 0.3720 - accuracy: 0.8545 - AUC: 0.7363\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 107us/sample - loss: 0.3991 - accuracy: 0.8539 - AUC: 0.6450 - val_loss: 0.3809 - val_accuracy: 0.8552 - val_AUC: 0.7176\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 67us/sample - loss: 0.3745 - accuracy: 0.8557 - AUC: 0.7216 - val_loss: 0.3715 - val_accuracy: 0.8523 - val_AUC: 0.7302\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3689 - accuracy: 0.8557 - AUC: 0.7368 - val_loss: 0.3707 - val_accuracy: 0.8562 - val_AUC: 0.7375\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 69us/sample - loss: 0.3641 - accuracy: 0.8577 - AUC: 0.7466 - val_loss: 0.3705 - val_accuracy: 0.8570 - val_AUC: 0.7354\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 68us/sample - loss: 0.3579 - accuracy: 0.8597 - AUC: 0.7586 - val_loss: 0.3697 - val_accuracy: 0.8559 - val_AUC: 0.7303\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 71us/sample - loss: 0.3538 - accuracy: 0.8603 - AUC: 0.7672 - val_loss: 0.3727 - val_accuracy: 0.8506 - val_AUC: 0.7413\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 70us/sample - loss: 0.3497 - accuracy: 0.8599 - AUC: 0.7756 - val_loss: 0.3725 - val_accuracy: 0.8541 - val_AUC: 0.7286\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 73us/sample - loss: 0.3441 - accuracy: 0.8633 - AUC: 0.7835 - val_loss: 0.3710 - val_accuracy: 0.8536 - val_AUC: 0.7347\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 2s 76us/sample - loss: 0.3370 - accuracy: 0.8684 - AUC: 0.7950 - val_loss: 0.3737 - val_accuracy: 0.8525 - val_AUC: 0.7273\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 70us/sample - loss: 0.3313 - accuracy: 0.8685 - AUC: 0.8044 - val_loss: 0.3828 - val_accuracy: 0.8525 - val_AUC: 0.7194\n",
      "5120/5120 [==============================] - 0s 72us/sample - loss: 0.3700 - accuracy: 0.8523 - AUC: 0.7484\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 104us/sample - loss: 0.4060 - accuracy: 0.8518 - AUC: 0.6304 - val_loss: 0.3794 - val_accuracy: 0.8550 - val_AUC: 0.7115\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 69us/sample - loss: 0.3792 - accuracy: 0.8532 - AUC: 0.7168 - val_loss: 0.3799 - val_accuracy: 0.8483 - val_AUC: 0.7259\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 68us/sample - loss: 0.3716 - accuracy: 0.8542 - AUC: 0.7347 - val_loss: 0.3738 - val_accuracy: 0.8572 - val_AUC: 0.7278\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 68us/sample - loss: 0.3662 - accuracy: 0.8552 - AUC: 0.7466 - val_loss: 0.3720 - val_accuracy: 0.8567 - val_AUC: 0.7315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 67us/sample - loss: 0.3618 - accuracy: 0.8562 - AUC: 0.7560 - val_loss: 0.3695 - val_accuracy: 0.8567 - val_AUC: 0.7355\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3573 - accuracy: 0.8572 - AUC: 0.7639 - val_loss: 0.3753 - val_accuracy: 0.8567 - val_AUC: 0.7278\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3545 - accuracy: 0.8590 - AUC: 0.7700 - val_loss: 0.3755 - val_accuracy: 0.8580 - val_AUC: 0.7319\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3474 - accuracy: 0.8626 - AUC: 0.7815 - val_loss: 0.3759 - val_accuracy: 0.8525 - val_AUC: 0.7257\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3417 - accuracy: 0.8637 - AUC: 0.7912 - val_loss: 0.3910 - val_accuracy: 0.8452 - val_AUC: 0.7222\n",
      "Epoch 10/20\n",
      "20480/20480 [==============================] - 1s 67us/sample - loss: 0.3373 - accuracy: 0.8672 - AUC: 0.7977 - val_loss: 0.3861 - val_accuracy: 0.8472 - val_AUC: 0.7122\n",
      "5120/5120 [==============================] - 0s 67us/sample - loss: 0.3633 - accuracy: 0.8574 - AUC: 0.7507\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 99us/sample - loss: 0.3999 - accuracy: 0.8538 - AUC: 0.6472 - val_loss: 0.3820 - val_accuracy: 0.8548 - val_AUC: 0.7178\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 64us/sample - loss: 0.3761 - accuracy: 0.8549 - AUC: 0.7199 - val_loss: 0.3728 - val_accuracy: 0.8545 - val_AUC: 0.7286\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 69us/sample - loss: 0.3671 - accuracy: 0.8567 - AUC: 0.7415 - val_loss: 0.3789 - val_accuracy: 0.8544 - val_AUC: 0.7380\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 69us/sample - loss: 0.3637 - accuracy: 0.8565 - AUC: 0.7483 - val_loss: 0.3671 - val_accuracy: 0.8562 - val_AUC: 0.7368\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 71us/sample - loss: 0.3604 - accuracy: 0.8587 - AUC: 0.7525 - val_loss: 0.3739 - val_accuracy: 0.8548 - val_AUC: 0.7340\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 2s 76us/sample - loss: 0.3557 - accuracy: 0.8594 - AUC: 0.7640 - val_loss: 0.3687 - val_accuracy: 0.8572 - val_AUC: 0.7370\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 2s 76us/sample - loss: 0.3510 - accuracy: 0.8615 - AUC: 0.7714 - val_loss: 0.3728 - val_accuracy: 0.8564 - val_AUC: 0.7344\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 2s 79us/sample - loss: 0.3444 - accuracy: 0.8655 - AUC: 0.7806 - val_loss: 0.3758 - val_accuracy: 0.8498 - val_AUC: 0.7332\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 2s 83us/sample - loss: 0.3415 - accuracy: 0.8664 - AUC: 0.7858 - val_loss: 0.3790 - val_accuracy: 0.8484 - val_AUC: 0.7238\n",
      "5120/5120 [==============================] - 1s 156us/sample - loss: 0.3737 - accuracy: 0.8529 - AUC: 0.7410\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 116us/sample - loss: 0.4022 - accuracy: 0.8528 - AUC: 0.6451 - val_loss: 0.3782 - val_accuracy: 0.8566 - val_AUC: 0.7151\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 71us/sample - loss: 0.3784 - accuracy: 0.8532 - AUC: 0.7194 - val_loss: 0.3790 - val_accuracy: 0.8527 - val_AUC: 0.7339\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 2s 75us/sample - loss: 0.3696 - accuracy: 0.8554 - AUC: 0.7396 - val_loss: 0.3717 - val_accuracy: 0.8573 - val_AUC: 0.7265\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 72us/sample - loss: 0.3656 - accuracy: 0.8562 - AUC: 0.7477 - val_loss: 0.3670 - val_accuracy: 0.8548 - val_AUC: 0.7394\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 73us/sample - loss: 0.3615 - accuracy: 0.8571 - AUC: 0.7563 - val_loss: 0.3697 - val_accuracy: 0.8533 - val_AUC: 0.7317\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 72us/sample - loss: 0.3563 - accuracy: 0.8597 - AUC: 0.7663 - val_loss: 0.3759 - val_accuracy: 0.8527 - val_AUC: 0.7373\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 1s 72us/sample - loss: 0.3507 - accuracy: 0.8616 - AUC: 0.7762 - val_loss: 0.3779 - val_accuracy: 0.8514 - val_AUC: 0.7305\n",
      "Epoch 8/20\n",
      "20480/20480 [==============================] - 1s 71us/sample - loss: 0.3465 - accuracy: 0.8628 - AUC: 0.7833 - val_loss: 0.3793 - val_accuracy: 0.8495 - val_AUC: 0.7278\n",
      "Epoch 9/20\n",
      "20480/20480 [==============================] - 1s 70us/sample - loss: 0.3397 - accuracy: 0.8674 - AUC: 0.7924 - val_loss: 0.3789 - val_accuracy: 0.8544 - val_AUC: 0.7248\n",
      "5120/5120 [==============================] - 0s 70us/sample - loss: 0.3609 - accuracy: 0.8586 - AUC: 0.7464\n",
      "Train on 20480 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "20480/20480 [==============================] - 2s 104us/sample - loss: 0.3977 - accuracy: 0.8533 - AUC: 0.6549 - val_loss: 0.3782 - val_accuracy: 0.8550 - val_AUC: 0.7155\n",
      "Epoch 2/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3755 - accuracy: 0.8534 - AUC: 0.7242 - val_loss: 0.3729 - val_accuracy: 0.8577 - val_AUC: 0.7298\n",
      "Epoch 3/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3678 - accuracy: 0.8565 - AUC: 0.7407 - val_loss: 0.4035 - val_accuracy: 0.8550 - val_AUC: 0.7267\n",
      "Epoch 4/20\n",
      "20480/20480 [==============================] - 1s 65us/sample - loss: 0.3646 - accuracy: 0.8568 - AUC: 0.7464 - val_loss: 0.3801 - val_accuracy: 0.8561 - val_AUC: 0.7217\n",
      "Epoch 5/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3576 - accuracy: 0.8598 - AUC: 0.7593 - val_loss: 0.3759 - val_accuracy: 0.8530 - val_AUC: 0.7243\n",
      "Epoch 6/20\n",
      "20480/20480 [==============================] - 1s 66us/sample - loss: 0.3548 - accuracy: 0.8599 - AUC: 0.7658 - val_loss: 0.3784 - val_accuracy: 0.8525 - val_AUC: 0.7231\n",
      "Epoch 7/20\n",
      "20480/20480 [==============================] - 2s 76us/sample - loss: 0.3473 - accuracy: 0.8639 - AUC: 0.7793 - val_loss: 0.3766 - val_accuracy: 0.8522 - val_AUC: 0.7223\n",
      "5120/5120 [==============================] - 0s 79us/sample - loss: 0.3778 - accuracy: 0.8539 - AUC: 0.7261\n",
      "Train on 25600 samples, validate on 6400 samples\n",
      "Epoch 1/20\n",
      "25600/25600 [==============================] - 2s 93us/sample - loss: 0.3977 - accuracy: 0.8525 - AUC: 0.6564 - val_loss: 0.3782 - val_accuracy: 0.8544 - val_AUC: 0.7233\n",
      "Epoch 2/20\n",
      "25600/25600 [==============================] - 2s 60us/sample - loss: 0.3743 - accuracy: 0.8542 - AUC: 0.7266 - val_loss: 0.3677 - val_accuracy: 0.8566 - val_AUC: 0.7361\n",
      "Epoch 3/20\n",
      "25600/25600 [==============================] - 2s 65us/sample - loss: 0.3676 - accuracy: 0.8555 - AUC: 0.7417 - val_loss: 0.3724 - val_accuracy: 0.8573 - val_AUC: 0.7370\n",
      "Epoch 4/20\n",
      "25600/25600 [==============================] - 2s 64us/sample - loss: 0.3638 - accuracy: 0.8570 - AUC: 0.7507 - val_loss: 0.3681 - val_accuracy: 0.8561 - val_AUC: 0.7376\n",
      "Epoch 5/20\n",
      "25600/25600 [==============================] - 2s 64us/sample - loss: 0.3602 - accuracy: 0.8575 - AUC: 0.7562 - val_loss: 0.3716 - val_accuracy: 0.8550 - val_AUC: 0.7354\n",
      "Epoch 6/20\n",
      "25600/25600 [==============================] - 2s 63us/sample - loss: 0.3576 - accuracy: 0.8593 - AUC: 0.7627 - val_loss: 0.3684 - val_accuracy: 0.8566 - val_AUC: 0.7353\n",
      "Epoch 7/20\n",
      "25600/25600 [==============================] - 2s 60us/sample - loss: 0.3534 - accuracy: 0.8616 - AUC: 0.7698 - val_loss: 0.3704 - val_accuracy: 0.8512 - val_AUC: 0.7392\n",
      "CPU times: user 15min 17s, sys: 3min 2s, total: 18min 19s\n",
      "Wall time: 8min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8b7d69c3d0>,\n",
       "             param_grid={'dropout': [True], 'n_hidden_add': [2, 3],\n",
       "                         'n_neurons1': [200, 300], 'n_neurons2': [100, 200],\n",
       "                         'n_neurons_add': [30]})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use early stopping if model does not improve after 5 epochs\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "DNN_grid_search.fit(X_train_train_np, y_train_train_np, epochs=20,\n",
    "                validation_data=(X_train_val_np, y_train_val_np),\n",
    "                callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': True,\n",
       " 'n_hidden_add': 2,\n",
       " 'n_neurons1': 300,\n",
       " 'n_neurons2': 100,\n",
       " 'n_neurons_add': 30}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_best = DNN_grid_search.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_220 (Dense)            (None, 300)               54300     \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 88,391\n",
      "Trainable params: 88,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DNN_best.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25600/25600 [==============================] - 1s 28us/sample - loss: 0.3576 - accuracy: 0.8582 - AUC: 0.7658\n",
      "deep neural network best Train loss: \t0.3576\n",
      "deep neural network best Train accuracy: \t0.8582\n",
      "deep neural network best Train AUC: \t0.7658\n"
     ]
    }
   ],
   "source": [
    "# Evaluate train set\n",
    "DNN_train_loss_best, DNN_train_acc_best, DNN_train_auc_best = DNN_best.evaluate(X_train_train_np, y_train_train_np)\n",
    "print('deep neural network best Train loss: \\t%0.4f' % DNN_train_loss_best)\n",
    "print('deep neural network best Train accuracy: \\t%0.4f' % DNN_train_acc_best)\n",
    "print('deep neural network best Train AUC: \\t%0.4f' % DNN_train_auc_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 DNN Test optimized model against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3594 - accuracy: 0.8627 - AUC: 0.7356\n",
      "deep neural network best Test loss: \t0.3594\n",
      "deep neural network best Test accuracy: \t0.8627\n",
      "deep neural network best Test AUC: \t0.7356\n"
     ]
    }
   ],
   "source": [
    "# Evaluate against test set\n",
    "DNN_test_loss_best, DNN_test_acc_best, DNN_test_auc_best = DNN_best.evaluate(X_test_np, y_test_np)\n",
    "print('deep neural network best Test loss: \\t%0.4f' % DNN_test_loss_best)\n",
    "print('deep neural network best Test accuracy: \\t%0.4f' % DNN_test_acc_best)\n",
    "print('deep neural network best Test AUC: \\t%0.4f' % DNN_test_auc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict label using predict_classes\n",
    "y_pred_test_DNN = (DNN_best.predict(X_test_np) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93      6883\n",
      "         1.0       0.59      0.05      0.10      1117\n",
      "\n",
      "    accuracy                           0.86      8000\n",
      "   macro avg       0.73      0.52      0.51      8000\n",
      "weighted avg       0.83      0.86      0.81      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_test_DNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6842   41]\n",
      " [1057   60]]\n"
     ]
    }
   ],
   "source": [
    "# Examine confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred_test_DNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 DNN Evaluate AUC for ROC and PR for performance against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find probability estimates\n",
    "y_pred_proba_test_best_DNN = DNN_best.predict(X_test_np) # use predict for probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate false positive rate and true positive rate:\n",
    "DNN_fpr_best, DNN_tpr_best, DNN_thresholds_roc_best = roc_curve(y_test_np, y_pred_proba_test_best_DNN)\n",
    "\n",
    "# # Calculate precision and recall\n",
    "DNN_precision_best, DNN_recall_best, DNN_thresholds_pr_best = precision_recall_curve(y_test_np, y_pred_proba_test_best_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Precision-Recall curve for clf_best:\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.step(DNN_recall_best, DNN_precision_best, label='Precision-recall curve (area = %0.4f)' % auc(DNN_recall_best, DNN_precision_best))\n",
    "plt.title('deep neural network model: Precision-recall curve', size=13)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='lower left', fontsize=13)\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlim([-0.05, 1.05])\n",
    "\n",
    "# Plot ROC curve for clf_best:\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(DNN_fpr_best, DNN_tpr_best, label='ROC curve (area = %0.4f)' % auc(DNN_fpr_best, DNN_tpr_best))\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.title('deep neural network model: ROC curve', size=13)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlim([-0.05, 1.05])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7357137347851823"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Area under curve for ROC\n",
    "auc(DNN_fpr_best, DNN_tpr_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32895689022179403"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Area under precision-recall curve\n",
    "auc(DNN_recall_best, DNN_precision_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test input\n",
    "X_fininal_test = test_transformed.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for Logistic Regression\n",
    "y_LR = LR_best.predict(X_fininal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare np test input for DNN\n",
    "X_fininal_test_np = X_fininal_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for DNN\n",
    "y_DNN = (DNN_best.predict(X_fininal_test_np) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions to csv\n",
    "#pd.DataFrame(y_LR).to_csv(os.path.join(\"glmresults.csv\"))\n",
    "#pd.DataFrame(y_DNN).to_csv(os.path.join(\"nonglmresults.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Compare the modeling approaches\n",
    "\n",
    "To compare the two models, I will compare train accuracy, test accuracy, Area under ROC curve and Area under precision recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define estimates for the logistic regression model\n",
    "LR_train_accuracy_best = \"{0:0.4f}\".format(LR_best.score(X_train, y_train))\n",
    "LR_test_accuracy_best = \"{0:0.4f}\".format(LR_best.score(X_test, y_test))\n",
    "LR_AUC_ROC = \"{0:0.4f}\".format(auc(fpr, tpr))\n",
    "LR_AUC_precision_recall = \"{0:0.4f}\".format(auc(recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define estimates for the Deep neural network model\n",
    "DNN_train_accuracy_best = \"{0:0.4f}\".format(DNN_train_acc_best)\n",
    "DNN_test_accuracy_best = \"{0:0.4f}\".format(DNN_test_acc_best)\n",
    "DNN_AUC_ROC = \"{0:0.4f}\".format(auc(DNN_fpr_best, DNN_tpr_best))\n",
    "DNN_AUC_precision_recall = \"{0:0.4f}\".format(auc(DNN_recall_best, DNN_precision_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>AUC precision recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8581</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>0.3507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deep neural network</td>\n",
       "      <td>0.8582</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>0.7357</td>\n",
       "      <td>0.3290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Train Accuracy Test Accuracy AUC ROC  \\\n",
       "0  Logistic Regression         0.8581        0.8612  0.7538   \n",
       "1  Deep neural network         0.8582        0.8627  0.7357   \n",
       "\n",
       "  AUC precision recall  \n",
       "0               0.3507  \n",
       "1               0.3290  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a table to compare the estimates of the two models\n",
    "d = {'Model': ['Logistic Regression', 'Deep neural network'], \n",
    "     'Train Accuracy': [LR_train_accuracy_best, DNN_train_accuracy_best],\n",
    "     'Test Accuracy': [LR_test_accuracy_best, DNN_test_accuracy_best],\n",
    "     'AUC ROC':[LR_AUC_ROC,DNN_AUC_ROC],\n",
    "     'AUC precision recall':[LR_AUC_precision_recall,DNN_AUC_precision_recall]\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## executive summary\n",
    "\n",
    "Logistic regression (LR) model is a very basic model to solve classification problems. The model is easy to understand. With proper regulation, such as cross validation, overfitting can be avoided.  However, the model doesnâ€™t have enough flexibility to handle data set with complex variables,\n",
    "\n",
    "Deep neural network (DNN) model is used for various of classification problems. The model has enough flexibility to handle complex problems. The disadvantage of the model is it needs feed by large amount of the data to perform better than other models.\n",
    "\n",
    "My model recommendation will be based on 2 assumptions. One assumption is the ration of 0 and 1 in the test set is similar to the train set. The other one is the predictions of the minority class is more important than the predictions of majority class. Based on these 2 assumptions, I think the logistic regression algorithm perform better. The accuracies of the 2 algorithms are very close, based on the train and test accuracy, no overfitting. However, I choose logistic regression for following reasons. First, the AUCs of logistic regression are better than the AUCs of Deep Neural Network, which means the logistic regression model has better prediction of the minority class.  Second, the dataset is relatively small. Generally, Deep Neural Network performance less good than logistic regression in small dataset.\n",
    "\n",
    "Logistic regression model has a better prediction on the minority class on our dataset. For example, you are trying to hire a talent people. However, you need to interview 10 people. So, you donâ€™t care about the majority class are not qualified. You want to focus more on the minority which may qualified. So, the prediction for the minority is more important in this case. \n",
    "Back to our project, the prediction of the minority class is more important. So, we will use logistic regression model.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
